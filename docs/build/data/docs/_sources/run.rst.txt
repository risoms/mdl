
#### mdl-R33-analysis

.. code:: ipython3

    # Created on Sat May 1 15:12:38 2019  
    # @author: Semeon Risom  
    # @email: semeon.risom@gmail.com  
    # @url: https://semeon.io/d/R33-analysis  
    # @purpose: Hub for running processing and analysis.

.. code:: ipython3

    #---------------------------------------------------------------------------------------------------------------------imports
    #----core
    from pdb import set_trace as breakpoint
    import pandas as pd
    import gc, datetime, glob, string
    
    #----local
    from mdl import plot, processing, raw, redcap
    import mdl.model as model
    import mdl.settings as settings
    
    #----config
    config = settings.config
    filters = settings.config['filters']
    #set parameters
    config['task'] = 'gRT'
    config['type'] = 'eyetracking'
    config['single_subject'] = False
    config['single_trial'] = False
    
    # set current date
    date_start = []; date_end = []
    date_now  = datetime.datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')

.. code:: ipython3

    #------------------------------------------------------------------------------------------------------------------------init
    processing = processing(config, filters, is_library=False)
    console = processing.console

.. code:: ipython3

    #-------------------------------------------------------------------------------------------------------------------get pydoc
    is_pydoc = False
    if is_pydoc:
        build = '/Users/mdl-admin/Desktop/R33-analysis-master/output/analysis/html/guide'
        source = '/Users/mdl-admin/Desktop/R33-analysis-master/output/docs/source'
        path = '/Users/mdl-admin/Desktop/R33-analysis-master/output/docs'
        processing.pydoc(path=path, build=build, source=source, copy=True) if __name__ == '__main__' else None
    pass

.. code:: ipython3

    #-------------------------------------------------------------------------------------------------import raw data from server
    is_rawdata = False
    if is_rawdata:
        import pytz
        print(console['red'] + 'Step: importing raw data from server' + console['ENDC'])
    	#----login
        hostname = 'panel.utweb.utexas.edu'
        username = "utw10623"
        password = "mdlcla"
        #----paths
        log_path = config['output']
        save_path = config['output'] + '/raw/'
        r33_path = '/home/utweb/utw10623/public_html/a/r33/src/csv/data/subject'
        gRT_path = '/home/utweb/utw10623/public_html/a/gRT/1/src/csv/data/subject'
        l_exp = [{'path':r33_path,'task':'r33','save':'r33'}, {'path':gRT_path,'task':'gRT','save':'gRT'}]
    
        #----start
        raw = raw()
        download_date = raw.download(l_exp=l_exp, log_path=log_path, save_path=save_path, hostname=hostname, 
                                     username=username, password=password)
        
    	#----storing download date
        download_date = {k:v for x in download_date for k,v in x.items()}[config['task']][0]
        #convert unix to ISO
        tz = pytz.timezone('US/Central')
        date = datetime.datetime.fromtimestamp(download_date, tz).replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')
        #append
        date_end.append({'rawdata': date})
        del raw, date, tz
    pass

.. code:: ipython3

    #----------------------------------------------------------------------------------------------------------import REDCap data
    is_redcap = False
    if is_redcap:
        print(console['red'] + 'Step: importing redcap data' + console['ENDC'])
        redcap_url = 'https://redcap.prc.utexas.edu/redcap/api/'
        redcap_token = 'D04484634409375EA8CC34F5B71BC14A'
        demop = config['output'] + "/analysis/demographics.csv"
        cesdp = config['output'] + "/analysis/cesd_rrs.csv"
        mmpip = config['output'] + "/analysis/mmpi.csv"
        #cesd data
        redcap.cesd(path=cesdp, token=redcap_token, url=redcap_url, report_id='5485')
        #demographics data
        redcap.demographics(path=demop, token=redcap_token, url=redcap_url, report_id='5487')
        #mmpi data
        redcap.mmpi(path=mmpip, token=redcap_token, url=redcap_url, report_id='5486')
        date_end.append({'redcap':'%s'%(datetime.datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S'))})
        del demop, cesdp, mmpip, redcap
    pass

.. code:: ipython3

    #--------------------------------------------------------------------------start preprocessing behavioral or eyetracking data
    is_preprocessing = False
    if is_preprocessing:
        print(console['red'] + 'Step: preprocessing data' + console['ENDC'])
        #defining parameters
        path = config['output'] + "/raw/"
        single_subject = False
        single_trial = False
        subject = 103
        trial = 35
        #if single subject, single trial
        if (config['single_subject']) and (config['single_trial']):
            print('processing: single subject, single trial')
            processing.run(path=path, task_type=config['type'], single_subject=True, single_trial=True, subject=subject, trial=trial)
        #else if single subject, all trials
        elif (config['single_subject']) and (not config['single_trial']):
            print('processing: single subject, all trials')
            processing.run(path=path, task_type=config['type'], single_subject=True, single_trial=False, subject=subject)
        #if all subjects, all trials
        elif (not config['single_subject']) and (not config['single_trial']):
            print('processing: all subjects, all trials')
            processing.run(path=path, task_type=config['type'], single_subject=False, single_trial=False, isMultiprocessing=True, cores=7)
        #finished	
        date_end.append({'preprocessing':'%s'%(datetime.datetime.now().replace(microsecond=0).isoformat())})
    pass
    #############################################################################################################################
    #############################################################################################################################
    #############################################################################################################################
    #############################################################################################################################
    #############################################################################################################################

.. code:: ipython3

    print(console['red'] + 'Step: demographics, plots, analysis' + console['ENDC'])
    #----summary statistics, plots, analysis
    if not is_preprocessing:
        #%%----------------------------------------------------------------------------------------------------------------------
        #------------------------------------------------------------------------------------------------------------get metadata
        print(console['red'] + 'processing metadata' + console['ENDC'])
        #file path
        fpath = config['output'] + "/raw/" + config['task']
        #save path
        spath = config['output'] + "/analysis/subject_metadata.csv"
        subject_metadata = processing.subject_metadata(fpath=fpath, spath=spath)
        del fpath, spath, subject_metadata
        
        #%%----------------------------------------------------------------------------------------------------------------------
        #------------------------------------------------------------------------------------------------------------prepare data
        #exclude participants
        #exclude = [999999, 111111, 314, 298, 277, 262, 256, 255, 235, 206, 218, 211, 201, 193, 183, 140, 120, 103, 98, 94, 84, 60, 16, 12]
        exclude = [999999, 111111]
        print(console['red'] + 'excluding participants: %s'%(exclude) + console['ENDC'])
        
        #read demographics and rename id="participant"
        p_demo = config['output'] + "/analysis/demographics.csv"
        df_demographics = pd.read_csv(p_demo, float_precision='high')
        ##exclude participants
        df_demographics = df_demographics[~df_demographics['participant'].isin(exclude)]
        #create gender column
        df_demographics['gender'] = df_demographics.apply(lambda x: 'female' if (x['female'] == 1 and x['male'] == 0) else 
                                                          ('male' if (x['male'] == 1 and x['female'] == 0) else 'other'), axis=1)
        #replace eye color
        color=['Light Gray','Gray','Light Blue','Blue','Violet','Blue-Green','Green','Amber','Hazel',
        'Light Brown','Dark Brown','Black', 'Other']
        df_demographics['eye_color'] = df_demographics['eye_color'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], color)
        
        ##-------read cesd and rename id="participant"
        p_cesd = config['output'] + "/analysis/cesd_rrs.csv"
        df_cesd = pd.read_csv(p_cesd, float_precision='high')
        df_cesd = df_cesd.rename(columns={'record_id':'participant'})
        ##group cesd scores #bionomial
        df_cesd['cesd_group'] = df_cesd.apply(lambda x: 1 if (x['cesd_score'] > 15) else 0, axis=1)
        df_cesd['cesd_group_'] = df_cesd.apply(lambda x: 'High' if (x['cesd_score'] > 15) else 'Low', axis=1)
        ##exclude participants
        df_cesd = df_cesd[~df_cesd['participant'].isin(exclude)]
    
        ##-------read mmpi
        p_mmpi = config['output'] + "/analysis/mmpi.csv"
        df_mmpi = pd.read_csv(p_mmpi, float_precision='high')
        df_mmpi = df_mmpi.rename(columns={'record_id':'participant'})
        ##exclude participants
        df_mmpi = df_mmpi[~df_mmpi['participant'].isin(exclude)]
        
        ##-------read subject metadata
        p_subject = config['output'] + "/analysis/subject_metadata.csv"
        df_metadata = pd.read_csv(p_subject, float_precision='high')
        ##drop duplicate participant listings
        df_metadata = df_metadata.drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
        #start and end dates
        date_start.append({'metadata':'%s'%(df_metadata['date'].min())})
        date_end.append({'metadata':'%s'%(df_metadata['date'].max())})
        ##exclude participants
        df_metadata = df_metadata[~df_metadata['participant'].isin(exclude)]
        #r#ename variables
        df_metadata = df_metadata.rename(columns={"isWindowSuccess": "is_calibrated"})
        
        ##-------read bias summary and rename id="participant"
        #if eyetracking
        if config['type'] == 'eyetracking': p_bias = config['output'] + "/bias/eyetracking_bias.csv"
        #if behavioral
        else: p_bias = config['output'] + "/bias/behavioral_bias.csv"
        
        #load
        df_bias = pd.read_csv(p_bias, float_precision='high')
        df_bias = df_bias.rename(columns={'id':'participant'})
        ###drop unusual data
        df_bias = df_bias.drop(df_bias[(df_bias['trialType'].isnull())].index)
        ##set dp_bias and gaze_bias as float
        df_bias['dp_bias'] = df_bias['dp_bias'].astype(float)
        if config['type'] == 'eyetracking': df_bias['gaze_bias'] = df_bias['gaze_bias'].astype(float)
        
        #set trialtype as text
        df_bias['trialType_'] = df_bias['trialType']
        df_bias['trialType'] = df_bias.apply(lambda x: 1 if (x['trialType'] == 'pofa') else 0, axis=1)
        ##exclude participants
        df_bias = df_bias[~df_bias['participant'].isin(exclude)]
        
        ##-------getting demographic data
        df_s = df_metadata.merge(df_cesd,on='participant').merge(df_demographics,on='participant')
        
        ##-------merge
        df = df_bias.merge(df_cesd,on='participant').merge(df_metadata,on='participant').merge(df_demographics,on='participant')
        #exclude participants
        df = df[~df['participant'].isin(exclude)]
        #rename columns
        ##rename microsoft os to msos, mac os to macos
        df['os'].replace(['Microsoft Windows', 'macOS','Chrome OS'], ['msos', 'macos', 'cos'], inplace=True)
        
        ##-------calculate difference between real stimulus, dotloc onset and real value #then merge medians with df
        merge = ['race','gender']
        df_error, onset_error, drop = processing.onset_diff(df0=df, merge=merge, cores=7)
        ##combine exclude lists
        exclude = drop + exclude
        
        ##-------final version of df
        #merge
        df = pd.merge(df, df_error[['TrialNum_','m_rt','accuracy','m_diff_dotloc','m_diff_stim','participant']]\
                      .drop_duplicates(subset="participant", keep="first"), how='left', on='participant')
    
        ##export for seperate analysis in r
        csv_path = config['output'] + "/analysis/final_data.csv"
        print(console['red'] + 'Step: export for R analysis: %s'%(csv_path) + console['ENDC'])
        df.to_csv(csv_path, index=None)        
    
        ##--------number of subjects
        ##demographics
        subjects_demographics = df_demographics.shape[0]
        ###task
        subjects_task = df_metadata.shape[0]
        ###eyetracking
        subjects_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True].shape[0]
        l_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True]['participant'].astype('int').to_list()
        ###eyetracking
        subjects_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True].shape[0]
        l_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True]['participant'].astype('int').to_list()
        ###behavioral
        subjects_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False].shape[0]
        l_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False]['participant'].astype('int').to_list()
        ##cesd
        subjects_cesd = df_cesd.shape[0]
        ##cesd
        subjects_mmpi = df_mmpi.shape[0]
    
        ###get actual participants used in analysis
        subjects_eyetracking_used = len(glob.glob(config['output'] + "/tlbs/eyetracking/*.csv"))
        subjects_behavioral_used = len(glob.glob(config['output'] + "/tlbs/behavioral/*.csv"))
                    
        ##get subjects used
        if config['type'] == 'eyetracking':
            subjects_used = subjects_eyetracking_used
        else:
            subjects_used = subjects_behavioral_used
        
        ##--------date
        date_start = dict((key,d[key]) for d in date_start for key in d)
        date_end = dict((key,d[key]) for d in date_end for key in d)
        
        del p_bias, p_cesd, p_demo, p_mmpi, p_subject, color, csv_path
        
        is_demographic = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #--------------------------------------------------------------------------------------------------demographic statistics
        if is_demographic:
            #-----------------------------get max, min values
            #drop non-eyetracking participants
            df_d = df_s[df_s['participant'].isin(l_eyetracking)]
            #cesd high
            df_dh = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset="participant", keep="first")
            #cesd low
            df_dl = df_d.loc[df_d['cesd_score'] <= 15].drop_duplicates(subset="participant", keep="first")
            
            #get total used
            total = len(l_eyetracking)
            
            #-----------------------------descriptive demographic stats
            print(console['red'] + 'Step: descriptive demographic' + console['ENDC'])
            rows = []
            ##--------age
            rows.append(["Age","mean (SD)", 
                         '%s (%s)'%(str(round(df_dl['age'].mean(),1)),str(round(df_dl['age'].std(),1))),
                         '%s (%s)'%(str(round(df_dh['age'].mean(),1)),str(round(df_dh['age'].std(),1)))])
            
            ##--------race ##.sort_index(axis=0)
            eyecolor_ = df_d.drop_duplicates(subset="participant", keep="first").loc[:,'eye_color'].value_counts()
            for index, value in eyecolor_.items():
                if value != 0:
                    above_pct = '%.1f'%(round(value/total, 4)*100)
                    rows.append(["Eye Color","%s"%(index), '%s (%s)'%(value,above_pct),''])
            del eyecolor_
            
            ##--------vision
            #normal
            df_sum = df_d.loc[df_d['is_normalvision'] == True].drop_duplicates(subset="participant",keep="first").reset_index(drop=True)
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Vision", "Normal", '%s (%s)'%(count,above_pct),'a'])
            
            #corrective
            df_sum = df_d.loc[df_d['is_corrective'] == True].drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Vision", "Corrective", '%s (%s)'%(count,above_pct),'a'])
            
            ##--------handedness-right
            df_sum = df_d.loc[df_d['handedness'] == 'Right'].drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Handedness (Right)","Right", '%s (%s)'%(count,above_pct),'a'])
             
            ##--------gender
            ##female
            df_sum = df_d.loc[df_d['female'] == 1].drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Gender","Female", '%s (%s)'%(count,above_pct),'a'])
            
            ##male
            df_sum = df_d.loc[df_d['male'] == 1].drop_duplicates(subset="participant",keep="first").reset_index(drop=True)
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Gender","Male", '%s (%s)'%(count,above_pct),'a'])
             
            ##--------hispanic/latino
            df_sum = df_d[['hispanic','cesd_group_']].loc[df_d['hispanic'] == True].groupby(['cesd_group_']).agg(['count'])
            
            df_sum = df_d.loc[df_d['hispanic'] == True].drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
            df_d.groupby(['hispanic']).agg(['mean', 'count'])
            count = df_sum.shape[0]
            above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            rows.append(["Hispanic or Latino","(%)", '%s (%s)'%(count,above_pct),'a'])
            
            ##--------race ##.sort_index(axis=0)
            race = df_d.drop_duplicates(subset="participant", keep="first").loc[:,'race'].value_counts()
            for index, value in race.items():
                if value != 0:
                    above_pct = '%.1f'%(round(value/total, 4)*100)
                    rows.append(["Race","%s"%(index), '%s (%s)'%(value,above_pct),'a'])
            del race
            
            ##--------rrs
            rows.append(["Ruminative Response Scale","(SD)", 
                         '%s (%s)'%(str(round(df_dl['rrs_brooding'].mean(),1)), str(round(df_dl['rrs_brooding'].std(),1))),
                         '%s (%s)'%(str(round(df_dh['rrs_brooding'].mean(),1)), str(round(df_dh['rrs_brooding'].std(),1)))])
        
            ##--------CESD
            rows.append(["Center for Epidemiologic Studies Depression Scale","(SD)", 
                         '%s (%s)'%(str(round(df_dl['cesd_score'].mean(),1)), str(round(df_dl['cesd_score'].std(),1))),
                         '%s (%s)'%(str(round(df_dh['cesd_score'].mean(),1)), str(round(df_dh['cesd_score'].std(),1)))])
            ##CESD > 15
            # df_sum = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset="participant", keep="first").reset_index(drop=True)
            # count = df_sum.shape[0]
            # above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)
            # rows.append(['Center for Epidemiologic Studies Depression Scale', "CES-D > 15 (%)", '%s (%s)'%(count,above_pct)])
    
            #----- to df
            descriptive = pd.DataFrame(rows)
            descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'CES-D Low',3:'CESD High'})
            del descriptive.index.name
            
            ##create html
            html_name = 'demographic'
            html_path = config['output'] + "/analysis/html/%s.html"%(html_name)
            title = '<b>Table 1.</b> Participant characteristics (N = %s).'%(total)
            footnote = "<div id='note'>N = Sample size of eyetracking participants. Total participants = %s."%(subjects_task)
            html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source="demographic", title=title, footnote=footnote)
            del df_sum, index, value, above_pct, rows, html_path, title, html, html_name
        
        is_variables = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #-------------------------------------------------------------------------------------------------------list of variables
        if is_variables:
            print(console['red'] + 'Step: list of variables' + console['ENDC'])
            df_variables = processing.variables(df=df)
            
            ##create html
            html_name = 'definitions'
            html_path = config['output'] + "/analysis/html/%s.html"%(html_name)
            title = '<b>Table 1.</b> Task Variables and Definitions.'
            html = plot.html(config=config, df=df_variables, path=html_path, name=html_name, source="definitions", title=title)
        
        is_descriptive = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #------------------------------------------------------------------------------------------------------descriptive device
        if is_descriptive:
            print(console['red'] + 'Step: descriptive device' + console['ENDC'])
            rows = []
            ##--------os browser gpu type Webcam resolution Webcam message
            os_ = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'os'].value_counts()
            for index, value in os_.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Operating System","%s"%(index), '%s (%s)'%(value,above_pct)])
            del os_
            
            # ##--------os_version
            os_ = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'os_version'].value_counts()
            for index, value in os_.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Operating System version","%s"%(index), '%s (%s)'%(value,above_pct)])
            del os_
                
            ##--------browser
            browser = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'browser'].value_counts()
            for index, value in browser.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Browser","%s"%(index), '%s (%s)'%(value,above_pct)])
            del browser
            
            ##--------browser_version
            browser = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'browser_version'].value_counts()
            for index, value in browser.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Browser version","%s"%(index), '%s (%s)'%(value,above_pct)])
            del browser
            
            ##--------gpu type 
            gpu_type = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'gpu_type'].value_counts()
            for index, value in gpu_type.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["GPU type","%s"%(index), '%s (%s)'%(value,above_pct)])
            del gpu_type
            
            ##--------webcam brand
            gpu = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'gpu'].value_counts()
            for index, value in gpu.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["GPU model","%s"%(index), '%s (%s)'%(value,above_pct)])
            del gpu
            
            ##--------devicepixelratio
            display = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'devicePixelRatio'].value_counts().sort_index(axis=0)
            for index, value in display.items():
                index = '%.2f'%(round(index, 2))
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["devicePixelRatio","%s"%(index), '%s (%s)'%(value,above_pct)])
            del display
                
            ##--------display resolution
            display = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'monitorSize'].value_counts()
            for index, value in display.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Display resolution","%s"%(index), '%s (%s)'%(value,above_pct)])
            del display
            
            ##--------webcam message
            webcam_m = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'WebcamMessage'].value_counts()
            for index, value in webcam_m.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Webcam message","%s"%(index), '%s (%s)'%(value,above_pct)])
            
            ##--------webcam brand
            webcamb = df_s.drop_duplicates(subset="participant", keep="first").loc[:,'webcam_brand'].value_counts()
            for index, value in webcamb.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Webcam brand","%s"%(index), '%s (%s)'%(value,above_pct)])
            del webcamb   
            
            ##--------Webcam resolution
            webcamr = df_s[~df_s['webcamSize'].isin(['.x.'])].drop_duplicates(subset="participant",
                           keep="first").loc[:,'webcamSize'].value_counts()
            for index, value in webcamr.items():
                above_pct = '%.1f'%(round(value/subjects_task, 4)*100)
                rows.append(["Webcam resolution","%s"%(index), '%s (%s)'%(value,above_pct)])
            del webcamr
            
            #-------to df
            descriptive = pd.DataFrame(rows)
            descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})
            del descriptive.index.name
            
            #footnote
            footnote = [
            '<div class="description">\n',
                'During data collection, participants screen resolution were multiplied by the pixel density ratio, or\
                <a class="ref" href="https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio"><i>devicePixelRatio</i></a>\
                (i.e. width = screen.width / devicePixelRatio = 1920 * 1.5). This was done with the intent of storing true device \
                physical resolution. However to simplify analysis using webgazer, which uses the same initial value \
                to calculate gaze location, participants screen resolution is reverted back to its original value.\n',
            '</div>\n']
            footnote = ''.join(footnote)
            
            #create html
            html_name = 'device'
            html_path = config['output'] + "/analysis/html/%s.html"%(html_name)
            title = '<b>Table 1.</b> Device characteristics (N = %s).'%(subjects_task)
            html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source="device", title=title, footnote=footnote)
            del index, value, above_pct, rows, html_path, title, footnote, html, html_name
    
        is_task = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #--------------------------------------------------------------------------------------------------------descriptive task
        if is_task:
            print(console['red'] + 'Step: descriptive task' + console['ENDC'])
            rows = []
            ##--------step
            ##----demographic questionnaire
            rows.append(["Pre-Questionnaire", "Demographics", '%s (100.0)'%(subjects_demographics)])
            
            ##----cesd
            pre_ = '%s (%.1f)'%(subjects_cesd, (round(subjects_cesd/subjects_demographics, 4)*100))
            rows.append(["Pre-Questionnaire", "CES-D, RRS", '%s'%(pre_)])
            
            ##----task
            task_ = '%s (%.1f)'%(subjects_task, (round(subjects_task/subjects_demographics, 4)*100))
            rows.append(["Task", "Task", '%s'%(task_)])
            ###eyetracking
            eye_ = '%s (%.1f)'%(subjects_eyetracking, (round(subjects_eyetracking/subjects_task, 4)*100))
            rows.append(["Task", "Eyetracking", '%s'%(eye_)])
            ###eyetracking-used
            eyeused_ = '%s (%.1f)'%(subjects_eyetracking_used, (round(subjects_eyetracking_used/subjects_eyetracking, 4)*100))
            rows.append(["Task", "Used", '%s'%(eyeused_)])
            ###calibrated
            calibrated_ = '%s (%.1f)'%(subjects_calibrated, (round(subjects_calibrated/subjects_eyetracking, 4)*100))
            rows.append(["Task", "Calibrated", '%s'%(calibrated_)])
            ###behavioral
            behav_ = '%s (%.1f)'%(subjects_behavioral, (round(subjects_behavioral/subjects_task, 4)*100))
            rows.append(["Task", "Behavioral", '%s'%(behav_)])
            ###behavioral-used
            behavused_ = '%s (%.1f)'%(subjects_behavioral_used, (round(subjects_behavioral_used/subjects_behavioral, 4)*100))
            rows.append(["Task", "Used", '%s'%(behavused_)])
            
            ##----post assessment
            post_ = '%s (%.1f)'%(subjects_mmpi,(round(subjects_mmpi/subjects_demographics, 4)*100))
            rows.append(["Post-Questionnaire", "MMPI", '%s'%(post_)])
            
            #----to df
            descriptive = pd.DataFrame(rows)
            descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})
            del descriptive.index.name
            
            #----create html
            title = '<b>Table 1.</b> Schedule of Assessments.'
            ##footnote
            no_webcam = '%s, %s%%'%(webcam_m['NotFoundError'], '%1.f'%(round(webcam_m['NotFoundError']/subjects_task, 5)*100))
            blocked_webcam = '%s, %s%%'%(webcam_m['NotAllowedError'], '%1.f'%(round(webcam_m['NotAllowedError']/subjects_task, 5)*100))
            footnote = [
                '<div class="description">',
                'Data were collected from %s to %s. '%(date_start['metadata'],date_end['metadata']),
                'Participants unable to meet the eyetracking device requirements (e.g. Chrome and Firefox, webcam, laptop or desktop) ',
                'were placed in the behavioral version of dotprobe. Reasons include: participant dropout, ',
                'no webcam present on the device (n=%s), '%(no_webcam),
                'and blocked access of the webcam by the participants browser (n=%s)'%(blocked_webcam),
                '<a class="note" name="1"><sup>1</sup></a>.',
                '<br><br>',
                'Once completing the <i>Pre-Questionnaire</i> on REDCap, participants are redirected to the task. ',
                'Possible reasons for the drop off between <i>Pre-Questionnaire</i> (n=%s) \
                and <i>Task</i> (n=%s) samples can be due to: '%(subjects_cesd, subjects_task),
                'Technical error during redirect, and disinterest in continuing to participate in the experiment. ',
                '<br><br>',
                'Also of note is the amount of participants that were successfully calibrated (n=%s, %1.f%%).'%(subjects_calibrated,\
                                (round(subjects_calibrated/subjects_eyetracking, 4)*100)),
                '</div>'
            ]
            footnote = ''.join(footnote)
            
            #create html
            html_name = 'task'
            html_path = config['output'] + "/analysis/html/%s.html"%(html_name)
            html = plot.html(config=config, df=descriptive, path=html_path, source="task", name=html_name, title=title, footnote=footnote)
            
            del html_name,html_path,no_webcam,blocked_webcam,pre_,task_,calibrated_,behav_,webcam_m,behavused_,eye_,eyeused_,post_,descriptive
        
        is_summary = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #------------------------------------------------------------------------------------------------------------summary data
        if is_summary:
            print(console['red'] + 'Step: summary data' + console['ENDC'])
            rows = []
            #-----------------------------testing group by cesd group (high, low) and trial type mean
            df_mean_std = df[['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias','gaze_bias',
                           'init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center','mean_gaze_toward',
                           'mean_gaze_away','var_gaze_bias','dp_gaze_cor','trialType_',
                           'luminance','m_diff_stim','m_diff_dotloc']]
            
            #------------------------get list of columns
            l_var = list(df_mean_std)
            l_var_gaze = ['gaze_bias','init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center',
                          'mean_gaze_toward','mean_gaze_away','var_gaze_bias']
            l_var_dp = ['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias']
            
            ##--------crate rows
            df_mean_std = df_mean_std.groupby(['trialType_']).agg(['mean','std']).T.unstack(level=1)
            #collapse headers
            df_mean_std.columns = [' '.join(col).strip() for col in df_mean_std.columns.values]
            #combine columns
            df_mean_std['iaps'] = df_mean_std['iaps mean'].round(4).astype(str) + " (" + df_mean_std['iaps std'].round(4).astype(str) + ")"
            df_mean_std['pofa'] = df_mean_std['pofa mean'].round(4).astype(str) + " (" + df_mean_std['pofa std'].round(4).astype(str) + ")"
            #reindex and make new column for factor
            df_mean_std['variable'] = df_mean_std.index
            df_mean_std = df_mean_std.rename({'index': 'variable'}).reset_index(level=0,  drop=True)
            #create group column
            df_mean_std = df_mean_std.rename({'dp_gaze_corr': 'dpg_core'})
            df_mean_std['group'] = pd.np.where(df_mean_std['variable'].str.contains("gaze_"), "gaze",
                                   pd.np.where(df_mean_std['variable'].str.contains("dp_"), "dotprobe", "task"))
            
            df_mean_std = df_mean_std[['group','variable','iaps','pofa']]
            del df_mean_std.index.name
            
            #footnote
            footnote = [
            '<div class="description">',
            '</div>\n'
            ]
            footnote = ''.join(footnote)
            
            #create html
            html_name = 'summary' 
            html_path = config['output'] + "/analysis/html/%s.html"%(html_name)
            title = '<b>Table 1.</b> Summary Statistics (N = %s).'%(subjects_used)
            html = plot.html(config=config, df=df_mean_std, path=html_path, name=html_name, source="summary", title=title, footnote=footnote)
            
            del l_var, l_var_gaze, l_var_dp, rows, html_name, html_path, title, footnote, html
        
        is_plots = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #-------------------------------------------------------------------------------------------------------------------plots
        if is_plots:
            print(console['red'] + 'Step: plots' + console['ENDC'])
            is_single = True
            
            #----dropped
            #get pct drop
            pct_exclude = (round(len(exclude)/subjects_eyetracking, 4)*100)
            config['def_exclude'] = "To reduce the influence of outliers, participants %s were excluded due to 'Dotloc' or 'Stimulus \
            Onset Errors' 2.5 SD above the median (n=%s, %.1f%%, SD=2.5)."%(exclude, len(exclude), pct_exclude)
            
            #%%------------------------------------------------------------------------------------------------------------------
            #------------------------------------------------------------------------------------------------------single subject
            if is_single:
                """
                Resources:
                - https://media.springernature.com/original/springer-static/image/
                    art%3A10.3758%2Fs13428-017-0913-7/MediaObjects/13428_2017_913_Figa_HTML.gif
                """
                #-------------------------------------------------single subject bokeh coordinates (all trials)
                print(console['red'] + 'Step: bokeh_trial()' + console['ENDC'])
                subject = 31
                session = 0
                #data
                path_sns = config['output'] + "/process/data/eyetracking/%s_%s.csv"%(subject,session)
                df_single = pd.read_csv(path_sns, float_precision='high')
                #rename
                df_single = df_single.rename(columns={"LEmotion":"left_mood","REmotion":"right_mood"})
                #exclude columns
                df_single = df_single[['participant','session','subsession','TrialNum','timestamp','trialType','isCongruent',
                                        'left_mood','right_mood','monitorSize.px',
                                        'x','y','marker','sg_x','sg_y','sg_class',
                                        'sg_fix_all','sg_fix_index',
                                        'sg_all_bounds','sg_fix_bounds','fix_num',
                                        'left_bound','right_bound','dwell']]
                
                #get rois
                stim_bounds, roi_bounds = processing.roi(filters=filters, flt=filters[0][1], df=df_single, manual=True)
                #for each subject
                flt = 'sg'
                for idx in range(198):
                    #subset data
                    df_single_ = df_single[df_single['TrialNum'].isin([idx])].reset_index(drop=True)
                    #draw plot
                    bokeh_plot = plot.bokeh_trial(config=config, df=df_single_,stim_bounds=stim_bounds,roi_bounds=roi_bounds,flt='sg')
                    ##get is_congruent
                    isCongruent = "congruent" if df_single_['isCongruent'][0] == True else "incongruent"
                    #html
                    title = "(%s) Participant %s, session %s, trial "%(isCongruent, subject, session)
                    html_path = config['output'] + "/analysis/html/trial/%s_%s_%s.html"%(subject,session,idx)
                    html = plot.html(config=config, path=html_path, plots=bokeh_plot, source="bokeh", display="trial", trial=idx, title=title)
                                         
                del title, path_sns, bokeh_plot, df_single_, html_path, html, subject, session
                
                #-------------------------------------------------single subject calibration
                print(console['green'] + 'bokeh_calibration()' + console['ENDC'])
                #metadata
                subject = 'robin'
                session = '2' #1,2,3
                #data
                path_sns = config['output'] + "/analysis/calibration/%s_0_%s_calibration.csv"%(subject, session)
                df_calibration = pd.read_csv(path_sns, float_precision='high')
                
                #calibration and validation
                for event, full in zip(['isCalibrating','isValidating'],['calibration','validation']):
                    #subset data
                    df_calibration_ = df_calibration.loc[df_calibration['event'] == event].reset_index(drop=True)
                    #draw plot
                    bokeh_plot = plot.bokeh_calibration(config=config, df=df_calibration_)
                    #html
                    title = "Participant %s, session %s,"%(subject, session)
                    html_path = config['output'] + "/analysis/html/trial/%s_%s_%s.html"%(subject,session,full)
                    html = plot.html(config=config, path=html_path, plots=bokeh_plot, source="bokeh", display="calibration",
                                         trial=full, session=session, title=title)
                                     
                del title, path_sns, bokeh_plot, html_path, html
    
            is_density = True
            #%%------------------------------------------------------------------------------------------------------------------
            #--------------------------------------------------------------------------------------------------------density plot
            if is_density:
                print(console['red'] + 'Step: density_plot()' + console['ENDC'])
                #Computes and draws density plot (kernel density estimate), which is a smoothed version of the histogram. 
                #This is used as a gage for normality
                df_density = df[['trialType_','m_rt',
                                 'm_diff_dotloc','m_diff_stim','luminance',
                                 'rrs_brooding','cesd_score','cesd_group_',
                                 'dp_bias','n_dp_valid','gaze_bias','n_gaze_valid',
                                 'var_gaze_bias','final_gaze_bias']].loc[df['nested'] == 'subject']   
                
                #----exclude
                df_density = df_density[~df_density['participant'].isin(exclude)]   
                
                #file
                title = string.capwords('kernel density estimate')
                
                #create images
                density, html_plots = plot.density_plot(config=config, df=df_density, title=title)
                #description of plots
                intro = "The kernel density estimate (kde) is used here as a quick check of normality for each of the variables of \
                interest in the model. All data here has been nested by subject. %s"%(config['def_exclude'])
                #create html
                html_path = config['output'] + "/analysis/html/density.html"
                html = plot.html(config=config, path=html_path, plots=html_plots, source="plots", intro=intro)
                del density, intro, html_plots, html_path, html, title
                
            is_corr = True 
            #%%------------------------------------------------------------------------------------------------------------------
            #--------------------------------------------------------------------------------------------------correlation matrix
            if is_corr:
                print(console['red'] + 'Step: corr_matrix()' + console['ENDC'])
                #run correlation matrix
                df_corr = df[['dp_bias','n_dp_valid','var_dp_bias',
                              'gaze_bias','n_gaze_valid','var_gaze_bias','final_gaze_bias',
                              'rrs_brooding','cesd_score',
                              'm_rt','m_diff_dotloc','m_diff_stim',
                              'luminance']].loc[df['nested'] == 'subject']
                
                #file
                file = 'corr_matrix'
                method = 'spearman'
                title = string.capwords('%s correlation coefficient matrix (p-value).'%(method))
                
                path = config['output'] + "/analysis/html/%s.html"%(file)
                corr_matrix = plot.corr_matrix(config=config, df=df_corr, path=path, title=title, method=method)
                del path, corr_matrix
                    
                del file, title, method
            
            is_boxplot = True
            #%%------------------------------------------------------------------------------------------------------------------
            #-------------------------------------------------------------------------------------------------------------boxplot
            if is_boxplot:
                print(console['red'] + 'Step: boxplot()' + console['ENDC'])
                #----create temp df
                df_box = df[['dp_bias','gaze_bias','dp_gaze_cor','final_gaze_bias', 'participant','trialType_', 'cesd_group_', 'nested']]
                html_plots = []
    
                #----exclude
                df_box = df_box[~df_box['participant'].isin(exclude)]
                df_box_error = df_error[~df_error['participant'].isin(exclude)]
                
                #get pct drop
                pct_exclude = (round(len(exclude)/subjects_eyetracking, 4)*100)
                
                #analysis--------------------------------------------------------------------------------------------------------
                html_file = 'bias_boxplot'
                y=['dp_bias','gaze_bias','dp_gaze_cor','final_gaze_bias']
                #create plot
                intro = 'This was done with two purposes. \
                        1) To get general trends in the data. \
                        2) To identify potential outliers in the data that might warrent investigation. Participants that \
                        may need follow up are 999999, 111111, 314, 298, 256, 206, 218, 201, 193, 183, 140, 84, 60, 12. \
                        Note: All data here has either been collapsed by subject or trialType.'
                ##-------cesd
                df_box_ = df_box.loc[df['nested'] == 'subject']
                file = 'boxplot_cesd'
                x='cesd_group_'
                cat='analysis'
                title = 'Boxplots, CES-D Cutoff (N = %s, collapsed by subject)'%(subjects_used) 
                footnote = "Data collapsed by subject:trialType. %s"%(config['def_exclude'])
                sns_path = config['output'] + "/analysis/html/img/%s.png"%(file)
                plot.boxplot(config=config, df=df_box_, path=sns_path, x=x,y=y, cat=cat)
                html_plots.append({"title":title,"file":"%s.png"%(file),"footnote":footnote})
                
                ##-------trialType
                df_box_ = df_box.loc[df['nested'] == 'trialType']
                file = 'boxplot_trial'
                x='trialType_'
                cat='analysis'
                title = 'Boxplots, Trial Type (N = %s, collapsed by subject:trialType)'%(subjects_used)
                footnote = "Data collapsed by subject:trialType. %s"%(config['def_exclude'])
                sns_path = config['output'] + "/analysis/html/img/%s.png"%(file)
                plot.boxplot(config=config, df=df_box_, path=sns_path, x=x, y=y, cat=cat)
                html_plots.append({"title":title,"file":"%s.png"%(file),"footnote":footnote})
                
                #save folders
                html_path = config['output'] + "/analysis/html/%s.html"%(html_file)
                html = plot.html(config=config, path=html_path, plots=html_plots, source="plots", display="boxplot", intro=intro)
                del intro, html_file, file, title, sns_path, html_path, html, cat, x, y
             
                #timing----------------------------------------------------------------------------------------------------------
                html_plots = []
                html_file = 'rt_boxplot'
                x = ['race','gender','is_normalvision','os']
                cat = 'demographics'
                
                ##-------response time
                y = 'Key_Resp_rt'
                intro = 'This was done to compare differences in response time between os, webcamsize, gender, race and other factors.'
                footnote = "Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \
                races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s"%(config['def_exclude'])
                #create plot
                file = 'rt_boxplot'
                title = 'Boxplots, %s (N = %s)'%(y, subjects_used)
                sns_path = config['output'] + "/analysis/html/img/%s.png"%(file)
                plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x, y=y, cat=cat)
                html_plots.append({"title":title,"file":"%s.png"%(file),"footnote":footnote})
                
                ##-------diff_dotloc
                y = 'diff_dotloc'
                intro = 'This was done to compare differences between expected and true dotloc onset between os, webcamsize, \
                gender, race and other factors.'
                footnote = "Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \
                races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s"%(config['def_exclude'])
                #create plot
                file = 'dotloc_boxplot'
                title = 'Boxplots, %s (N = %s)'%(y, subjects_used)
                sns_path = config['output'] + "/analysis/html/img/%s.png"%(file)
                plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x,y=y, cat=cat)
                html_plots.append({"title":title,"file":"%s.png"%(file),"footnote":footnote})
                
                ##-------diff_stim
                y = 'diff_stim'
                intro = 'This was done to compare differences between expected and true stim onset between os, webcamsize, \
                gender, race and other factors.'
                footnote = "Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \
                races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s"%(config['def_exclude'])
                #create plot
                file = 'stim_boxplot'
                title = 'Boxplots, %s (N = %s)'%(y, subjects_used)
                sns_path = config['output'] + "/analysis/html/img/%s.png"%(file)
                plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x,y=y, cat=cat)
                html_plots.append({"title":title,"file":"%s.png"%(file),"footnote":footnote})
                
                #-------save folders
                html_path = config['output'] + "/analysis/html/%s.html"%(html_file)
                html = plot.html(config=config, path=html_path, plots=html_plots, source="plots", display="boxplot", intro=intro)
                del intro, html_file, file, title, html_path, html, cat, x, y, footnote
                
        is_analysis = True
        #%%----------------------------------------------------------------------------------------------------------------------
        #----------------------------------------------------------------------------------------------------------------analysis
        if is_analysis:
            print(console['red'] + 'Step: analysis' + console['ENDC'])
    
            """
            Resources:
            - https://stats.idre.ucla.edu/other/mult-pkg/whatstat/
            """
            
            is_dwell = True
            #%%------------------------------------------------------------------------------------------------------------------
            #---------------------------------------------------------------------------------------------------ANOVA: dwell time
            if is_dwell:
                print(console['red'] + 'Step: ANOVA (dwell time)' + console['ENDC'])
                #mixed model anova
                """
                Resources:
                - https://m-clark.github.io/docs/mixedModels/anovamixed.html
                - http://dwoll.de/rexrepos/posts/anovaMixed.html
                - https://rpsychologist.com/r-guide-longitudinal-lme-lmer
                - https://stats.stackexchange.com/questions/247582/repeated-measures-anova-in-r-errorsubject-vs-errorsubject-day
                - https://cran.r-project.org/web/packages/afex/vignettes/afex_anova_example.html#post-hoc-contrasts-and-plotting
                - http://www.let.rug.nl/nerbonne/teach/rema-stats-meth-seminar/presentations/Wieling-MixedModels-2011.pdf
                """
                #-----parameters
                y = 'dwell_time'
                f = '''%s ~ cesd_group * aoi + trialType + (1|participant)'''%(y)
                
                #----save data for access by R and for calculating dwell time
                output_file = "dwell_data.csv"
                output_path = config['output'] + "/analysis/"
                img_path = config['output'] + "/analysis/html/img/"
                html_path = config['output'] + "/analysis/html/"
            
    			#-----calculate dwell-time using multiprocessing
                # exclude participants
                df_ = df[~df['participant'].isin(exclude)]
    			# use __name__ to protect main module
                df_dwell, error_dwell = processing.dwell(df=df_, cores=7) if __name__ == '__main__' else None
                
    			#-----group by subject:trialType:aoi
                df_dwell = df_dwell.groupby(['participant','cesd_group','trialType','aoi'])['dwell_time'].mean().reset_index()
    
    			#-----run
                model, results, r = model.anova(config=config, df=df_dwell, y=y, f=f, output_file=output_file, 
                                    output_path=output_path, img_path=img_path, html_path=html_path, is_html=True)
            
            is_diff = True
            #%%------------------------------------------------------------------------------------------------------------------
            #---------------------------------------------------Negative-Binomial Poisson Regression: stimulus/dotloc onset error
            if is_diff:
                print(console['red'] + 'Step: Poisson Regression' + console['ENDC'])
            
                #--------------------negative-binomial poisson regression
                #-----parameters
                y = ['diff_dotloc','diff_stim'] #build models for each item in list
                #create function for each response variable
                for _y in y:
                    f = "%s ~ os + race + gender + trialType + TrialNum_ + (1|participant) + (TrialNum_|participant)"%(_y)
                
                #---------save data for access by R
                output_file = "onset_data.csv"
                output_path = config['output'] + "/analysis/"
                img_path = config['output'] + "/analysis/html/img/"
                html_path = config['output'] + "/analysis/html/"
                
                #-----exclude participants
                # exclude participants
                df_ = df_error[~df_error['participant'].isin(exclude)]
                
                #-----run
                model, results, r = model.glmer_nb(config=config, df=df_, y=y, f=f, exclude=exclude, total=subjects_eyetracking,
                                output_file=output_file, output_path=output_path, img_path=img_path, html_path=html_path, is_html=True)
            
            is_mixed = True
            #%%------------------------------------------------------------------------------------------------------------------
            #------------------------------------------------generalized linear mixed-effects logistic model with random effects
            if is_mixed:
                print(console['red'] + 'Step: Logistic Regression' + console['ENDC'])
                
                #-----parameters
                y = 'cesd_group'
                f = '''cesd_group ~ os + trialType + m_rt + 
                       dp_bias*n_dp_valid + gaze_bias*log(n_gaze_valid) + 
                       (1|participant)'''
                            
                #----save data for access by R and for calculating dwell time
                output_file = "logit_data.csv"
                output_path = config['output'] + "/analysis/"
                img_path = config['output'] + "/analysis/html/img/"
                html_path = config['output'] + "/analysis/html/"
                
                #-----group data by subject:trialType
                # exclude participants
                df_ = df[~df['participant'].isin(exclude)]
                # group
                df_ = df_.loc[df_['nested'] == 'trialType']
                
                #-----run
                model, results, r = model.logistic(config=config, df=df_, y=y, f=f, output_file=output_file, 
                               output_path=output_path, img_path=img_path, html_path=html_path, is_html=True)
        
        #----------------------------------------------------------------------------------------------------------------finished
        #---------------------------------------------------------------------------------------------------------garbage collect
        gc.collect()
        #---------------------------------------------------------------------------------------------------------quick functions
        #get list of columns
        #lst = list(df)
        #install pip package
        #from pip._internal import main as _main
        #_main(['install','statsmodels'])
        
        #----------------------------------------------------------------------------------------------------------iPython Magics
        #%matplotlib qt5
        #%matplotlib tk
        #%matplotlib inline
        
        #------------------------------------------------------------------------------------------------------------other magics
        #from pdb import set_trace as breakpoint
        #breakpoint()
        
        #------------------------------------------------------------------------------------------------------------profile code
        ##method 1 -- use within iPython interpreter
        #%load_ext snakeviz
        #%snakeviz runfile('C:/Users/sr38553/projects/work/eyelink_webgazer/py/run.py', 
        #wdir='C:/Users/sr38553/projects/work/eyelink_webgazer/py')
        
        ##method 2
        #from pycallgraph import PyCallGraph
        #from pycallgraph.output import GraphvizOutput
        #with PyCallGraph(output=GraphvizOutput()):
        #    df_all, cgxy_df, fgxy_df, trial = processing.run()
        
    
    
    
    
    
    
    
    
    

