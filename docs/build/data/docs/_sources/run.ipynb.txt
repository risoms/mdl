{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### mdl-R33-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created on Sat May 1 15:12:38 2019  \n",
    "# @author: Semeon Risom  \n",
    "# @email: semeon.risom@gmail.com  \n",
    "# @url: https://semeon.io/d/R33-analysis  \n",
    "# @purpose: Hub for running processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------------------------imports\n",
    "#----local\n",
    "from mdl import plot, processing, raw, redcap\n",
    "import mdl.model as model\n",
    "import mdl.settings as settings\n",
    "\n",
    "#----check if required libraries are available\n",
    "is_library = False\n",
    "if is_library:\n",
    "    settings.library()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------imports continued\n",
    "#----core\n",
    "from pdb import set_trace as breakpoint\n",
    "import pandas as pd\n",
    "import gc, glob, string, pytz\n",
    "from datetime import datetime\n",
    "\n",
    "#----config\n",
    "config = settings.config\n",
    "filters = settings.config['filters']\n",
    "#set parameters\n",
    "config['task'] = 'gRT'\n",
    "config['type'] = 'eyetracking'\n",
    "config['single_subject'] = False\n",
    "config['single_trial'] = False\n",
    "\n",
    "# set current date\n",
    "date_start = []; date_end = []\n",
    "date_now  = datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------------------------------------init\n",
    "processing = processing(config, filters)\n",
    "console = settings.console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------------create pydoc\n",
    "is_pydoc = True\n",
    "if is_pydoc:\n",
    "    build = '/Users/mdl-admin/Desktop/mdl-R33-analysis/output/analysis/html/docs'\n",
    "    source = '/Users/mdl-admin/Desktop/mdl-R33-analysis/docs/source'\n",
    "    path = '/Users/mdl-admin/Desktop/mdl-R33-analysis/docs'\n",
    "    processing.pydoc(path=path, build=build, source=source, copy=True) if __name__ == '__main__' else None\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------import raw data from server\n",
    "is_rawdata = False\n",
    "if is_rawdata:\n",
    "    print(console['red'] + 'Step: importing raw data from server' + console['ENDC'])\n",
    "\t#----login\n",
    "    hostname = 'panel.utweb.utexas.edu'\n",
    "    username = \"utw10623\"\n",
    "    password = \"mdlcla\"\n",
    "    #----path\n",
    "    log_path = config['output']\n",
    "    save_path = config['output'] + '/raw/'\n",
    "    r33_path = '/home/utweb/utw10623/public_html/a/r33/src/csv/data/subject'\n",
    "    gRT_path = '/home/utweb/utw10623/public_html/a/gRT/1/src/csv/data/subject'\n",
    "    l_exp = [{'path':r33_path,'task':'r33','save':'r33'}, {'path':gRT_path,'task':'gRT','save':'gRT'}]\n",
    "    #----start\n",
    "    raw = raw()\n",
    "    download_date = raw.download(l_exp=l_exp, log_path=log_path, save_path=save_path, hostname=hostname, username=username, password=password)\n",
    "\t#----storing download date\n",
    "    download_date = {k:v for x in download_date for k,v in x.items()}[config['task']][0]\n",
    "    #convert unix to ISO\n",
    "    tz = pytz.timezone('US/Central')\n",
    "    date = datetime.fromtimestamp(download_date, tz).replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    #append\n",
    "    date_end.append({'rawdata': date})\n",
    "    del raw, date, tz\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------------------------------------------import REDCap data\n",
    "is_redcap = False\n",
    "if is_redcap:\n",
    "    print(console['red'] + 'Step: importing redcap data' + console['ENDC'])\n",
    "    #----login, paths\n",
    "    redcap_url = 'https://redcap.prc.utexas.edu/redcap/api/'\n",
    "    redcap_token = 'D04484634409375EA8CC34F5B71BC14A'\n",
    "    demop = config['output'] + \"/analysis/demographics.csv\"\n",
    "    cesdp = config['output'] + \"/analysis/cesd_rrs.csv\"\n",
    "    mmpip = config['output'] + \"/analysis/mmpi.csv\"\n",
    "    #----cesd data\n",
    "    redcap.cesd(path=cesdp, token=redcap_token, url=redcap_url, report_id='5485')\n",
    "    #----demographics data\n",
    "    redcap.demographics(path=demop, token=redcap_token, url=redcap_url, report_id='5487')\n",
    "    #----mmpi data\n",
    "    redcap.mmpi(path=mmpip, token=redcap_token, url=redcap_url, report_id='5486')\n",
    "    date_end.append({'redcap':'%s'%(datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S'))})\n",
    "    del demop, cesdp, mmpip, redcap\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------start preprocessing behavioral or eyetracking data\n",
    "is_preprocessing = False\n",
    "if is_preprocessing:\n",
    "    print(console['red'] + 'Step: preprocessing data' + console['ENDC'])\n",
    "    #----parameters\n",
    "    path = config['output'] + \"/raw/\"\n",
    "    subject = 31\n",
    "    trial = 35\n",
    "    #----if single subject, single trial\n",
    "    if (config['single_subject']) and (config['single_trial']):\n",
    "        print('processing: single subject, single trial')\n",
    "        processing.run(path=path, task_type=config['type'], single_subject=True, single_trial=True, subject=subject, trial=trial)\n",
    "    #----else if single subject, all trials\n",
    "    elif (config['single_subject']) and (not config['single_trial']):\n",
    "        print('processing: single subject, all trials')\n",
    "        processing.run(path=path, task_type=config['type'], single_subject=True, single_trial=False, subject=subject)\n",
    "    #----if all subjects, all trials\n",
    "    elif (not config['single_subject']) and (not config['single_trial']):\n",
    "        print('processing: all subjects, all trials')\n",
    "        processing.run(path=path, task_type=config['type'], single_subject=False, single_trial=False, isMultiprocessing=True, cores=7)\n",
    "    #----finished\t\n",
    "    date_end.append({'preprocessing':'%s'%(datetime.now().replace(microsecond=0).isoformat())})\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'Step: demographics, plots, analysis' + console['ENDC'])\n",
    "#----summary statistics, plots, analysis\n",
    "if not is_preprocessing:\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------get metadata\n",
    "    print(console['red'] + 'processing metadata' + console['ENDC'])\n",
    "    #file path\n",
    "    fpath = config['output'] + \"/raw/\" + config['task']\n",
    "    #save path\n",
    "    spath = config['output'] + \"/analysis/subject_metadata.csv\"\n",
    "    subject_metadata = processing.subject_metadata(fpath=fpath, spath=spath)\n",
    "    del fpath, spath, subject_metadata\n",
    "    \n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------prepare data\n",
    "    #exclude participants\n",
    "    exclude = [999999, 111111]\n",
    "    print(console['red'] + 'preparing data: %s'%(exclude) + console['ENDC'])\n",
    "    \n",
    "    #read demographics and rename id=\"participant\"\n",
    "    p_demo = config['output'] + \"/analysis/demographics.csv\"\n",
    "    df_demographics = pd.read_csv(p_demo, float_precision='high')\n",
    "    ##exclude participants\n",
    "    df_demographics = df_demographics[~df_demographics['participant'].isin(exclude)]\n",
    "    #create gender column\n",
    "    df_demographics['gender'] = df_demographics.apply(lambda x: 'female' if (x['female'] == 1 and x['male'] == 0) else \n",
    "                                                      ('male' if (x['male'] == 1 and x['female'] == 0) else 'other'), axis=1)\n",
    "    #replace eye color\n",
    "    color=['Light Gray','Gray','Light Blue','Blue','Violet','Blue-Green','Green','Amber','Hazel',\n",
    "    'Light Brown','Dark Brown','Black', 'Other']\n",
    "    df_demographics['eye_color'] = df_demographics['eye_color'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], color)\n",
    "    \n",
    "    ##-------read cesd and rename id=\"participant\"\n",
    "    p_cesd = config['output'] + \"/analysis/cesd_rrs.csv\"\n",
    "    df_cesd = pd.read_csv(p_cesd, float_precision='high')\n",
    "    df_cesd = df_cesd.rename(columns={'record_id':'participant'})\n",
    "    ##group cesd scores #bionomial\n",
    "    df_cesd['cesd_group'] = df_cesd.apply(lambda x: 1 if (x['cesd_score'] > 15) else 0, axis=1)\n",
    "    df_cesd['cesd_group_'] = df_cesd.apply(lambda x: 'High' if (x['cesd_score'] > 15) else 'Low', axis=1)\n",
    "    ##exclude participants\n",
    "    df_cesd = df_cesd[~df_cesd['participant'].isin(exclude)]\n",
    "\n",
    "    ##-------read mmpi\n",
    "    p_mmpi = config['output'] + \"/analysis/mmpi.csv\"\n",
    "    df_mmpi = pd.read_csv(p_mmpi, float_precision='high')\n",
    "    df_mmpi = df_mmpi.rename(columns={'record_id':'participant'})\n",
    "    ##exclude participants\n",
    "    df_mmpi = df_mmpi[~df_mmpi['participant'].isin(exclude)]\n",
    "    \n",
    "    ##-------read subject metadata\n",
    "    p_subject = config['output'] + \"/analysis/subject_metadata.csv\"\n",
    "    df_metadata = pd.read_csv(p_subject, float_precision='high')\n",
    "    ##drop duplicate participant listings\n",
    "    df_metadata = df_metadata.drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "    #start and end dates\n",
    "    date_start.append({'metadata':'%s'%(df_metadata['date'].min())})\n",
    "    date_end.append({'metadata':'%s'%(df_metadata['date'].max())})\n",
    "    ##exclude participants\n",
    "    df_metadata = df_metadata[~df_metadata['participant'].isin(exclude)]\n",
    "    #r#ename variables\n",
    "    df_metadata = df_metadata.rename(columns={\"isWindowSuccess\": \"is_calibrated\"})\n",
    "    \n",
    "    ##-------read bias summary and rename id=\"participant\"\n",
    "    #if eyetracking\n",
    "    if config['type'] == 'eyetracking': p_bias = config['output'] + \"/bias/eyetracking_bias.csv\"\n",
    "    #if behavioral\n",
    "    else: p_bias = config['output'] + \"/bias/behavioral_bias.csv\"\n",
    "    \n",
    "    #load\n",
    "    df_bias = pd.read_csv(p_bias, float_precision='high')\n",
    "    df_bias = df_bias.rename(columns={'id':'participant'})\n",
    "    ###drop unusual data\n",
    "    df_bias = df_bias.drop(df_bias[(df_bias['trialType'].isnull())].index)\n",
    "    ##set dp_bias and gaze_bias as float\n",
    "    df_bias['dp_bias'] = df_bias['dp_bias'].astype(float)\n",
    "    if config['type'] == 'eyetracking': df_bias['gaze_bias'] = df_bias['gaze_bias'].astype(float)\n",
    "    \n",
    "    #set trialtype as text\n",
    "    df_bias['trialType_'] = df_bias['trialType']\n",
    "    df_bias['trialType'] = df_bias.apply(lambda x: 1 if (x['trialType'] == 'pofa') else 0, axis=1)\n",
    "    ##exclude participants\n",
    "    df_bias = df_bias[~df_bias['participant'].isin(exclude)]\n",
    "    \n",
    "    ##-------getting demographic data\n",
    "    df_s = df_metadata.merge(df_cesd,on='participant').merge(df_demographics,on='participant')\n",
    "    \n",
    "    ##-------merge\n",
    "    df = df_bias.merge(df_cesd,on='participant').merge(df_metadata,on='participant').merge(df_demographics,on='participant')\n",
    "    #exclude participants\n",
    "    df = df[~df['participant'].isin(exclude)]\n",
    "    #rename columns\n",
    "    ##rename microsoft os to msos, mac os to macos\n",
    "    df['os'].replace(['Microsoft Windows', 'macOS','Chrome OS'], ['msos', 'macos', 'cos'], inplace=True)\n",
    "    \n",
    "    ##-------calculate difference between real stimulus, dotloc onset and real value #then merge medians with df\n",
    "    merge = ['race','gender','is_normalvision','os','participant']\n",
    "    df_error, onset_error, drop = processing.onset_diff(df0=df, merge=merge, cores=7)\n",
    "    ##combine exclude lists\n",
    "    exclude = drop + exclude\n",
    "    \n",
    "    ##-------final version of df\n",
    "    #merge\n",
    "    df = pd.merge(df, df_error[['TrialNum_','m_rt','accuracy','m_diff_dotloc','m_diff_stim','participant']]\\\n",
    "                  .drop_duplicates(subset=\"participant\", keep=\"first\"), how='left', on='participant')\n",
    "\n",
    "    ##export for seperate analysis in r\n",
    "    csv_path = config['output'] + \"/analysis/final_data.csv\"\n",
    "    print(console['red'] + 'Step: export for R analysis: %s'%(csv_path) + console['ENDC'])\n",
    "    df.to_csv(csv_path, index=None)        \n",
    "\n",
    "    ##--------number of subjects\n",
    "    ##demographics\n",
    "    subjects_demographics = df_demographics.shape[0]\n",
    "    ###task\n",
    "    subjects_task = df_metadata.shape[0]\n",
    "    ###eyetracking\n",
    "    subjects_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True].shape[0]\n",
    "    l_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True]['participant'].astype('int').to_list()\n",
    "    ###eyetracking\n",
    "    subjects_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True].shape[0]\n",
    "    l_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True]['participant'].astype('int').to_list()\n",
    "    ###behavioral\n",
    "    subjects_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False].shape[0]\n",
    "    l_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False]['participant'].astype('int').to_list()\n",
    "    ##cesd\n",
    "    subjects_cesd = df_cesd.shape[0]\n",
    "    ##cesd\n",
    "    subjects_mmpi = df_mmpi.shape[0]\n",
    "\n",
    "    ###get actual participants used in analysis\n",
    "    subjects_eyetracking_used = len(glob.glob(config['output'] + \"/tlbs/eyetracking/*.csv\"))\n",
    "    subjects_behavioral_used = len(glob.glob(config['output'] + \"/tlbs/behavioral/*.csv\"))\n",
    "                \n",
    "    ##get subjects used\n",
    "    if config['type'] == 'eyetracking':\n",
    "        subjects_used = subjects_eyetracking_used\n",
    "    else:\n",
    "        subjects_used = subjects_behavioral_used\n",
    "        \n",
    "    ##--------date\n",
    "    date_start = dict((key,d[key]) for d in date_start for key in d)\n",
    "    date_end = dict((key,d[key]) for d in date_end for key in d)\n",
    "    \n",
    "    del p_bias, p_cesd, p_demo, p_mmpi, p_subject, color, csv_path\n",
    "    \n",
    "    is_demographic = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #--------------------------------------------------------------------------------------------------demographic statistics\n",
    "    if is_demographic:\n",
    "        #-----------------------------get max, min values\n",
    "        #drop non-eyetracking participants\n",
    "        df_d = df_s[df_s['participant'].isin(l_eyetracking)]\n",
    "        #cesd high\n",
    "        df_dh = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n",
    "        #cesd low\n",
    "        df_dl = df_d.loc[df_d['cesd_score'] <= 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n",
    "        \n",
    "        #get total used\n",
    "        total = len(l_eyetracking)\n",
    "        \n",
    "        #-----------------------------descriptive demographic stats\n",
    "        print(console['red'] + 'Step: descriptive demographic' + console['ENDC'])\n",
    "        rows = []\n",
    "        ##--------age\n",
    "        rows.append([\"Age\",\"mean (SD)\", \n",
    "                     '%s (%s)'%(str(round(df_dl['age'].mean(),1)),str(round(df_dl['age'].std(),1))),\n",
    "                     '%s (%s)'%(str(round(df_dh['age'].mean(),1)),str(round(df_dh['age'].std(),1)))])\n",
    "        \n",
    "        ##--------race ##.sort_index(axis=0)\n",
    "        eyecolor_ = df_d.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'eye_color'].value_counts()\n",
    "        for index, value in eyecolor_.items():\n",
    "            if value != 0:\n",
    "                above_pct = '%.1f'%(round(value/total, 4)*100)\n",
    "                rows.append([\"Eye Color\",\"%s\"%(index), '%s (%s)'%(value,above_pct),''])\n",
    "        del eyecolor_\n",
    "        \n",
    "        ##--------vision\n",
    "        #normal\n",
    "        df_sum = df_d.loc[df_d['is_normalvision'] == True].drop_duplicates(subset=\"participant\",keep=\"first\").reset_index(drop=True)\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        rows.append([\"Vision\", \"Normal\", '%s (%s)'%(count,above_pct),'a'])\n",
    "        \n",
    "        #corrective\n",
    "        df_sum = df_d.loc[df_d['is_corrective'] == True].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        rows.append([\"Vision\", \"Corrective\", '%s (%s)'%(count,above_pct),'a'])\n",
    "        \n",
    "        ##--------handedness-right\n",
    "        df_sum = df_d.loc[df_d['handedness'] == 'Right'].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        rows.append([\"Handedness (Right)\",\"Right\", '%s (%s)'%(count,above_pct),'a'])\n",
    "         \n",
    "        ##--------gender\n",
    "        ##female\n",
    "        df_sum = df_d.loc[df_d['female'] == 1].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        rows.append([\"Gender\",\"Female\", '%s (%s)'%(count,above_pct),'a'])\n",
    "        \n",
    "        ##male\n",
    "        df_sum = df_d.loc[df_d['male'] == 1].drop_duplicates(subset=\"participant\",keep=\"first\").reset_index(drop=True)\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        rows.append([\"Gender\",\"Male\", '%s (%s)'%(count,above_pct),'a'])\n",
    "         \n",
    "        ##--------        \n",
    "        df_sum = df_d.loc[df_d['hispanic'] == True].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "        df_d.groupby(['hispanic']).agg(['mean', 'count'])\n",
    "        count = df_sum.shape[0]\n",
    "        above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        #rows.append([\"Hispanic or Latino\",\"(%)\", '%s (%s)'%(count,above_pct),'a'])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #hispanic/latino-----------------------------------------------------------------------------------------------------\n",
    "        df_sum = df_d[['hispanic','cesd_group_']].loc[df_d['hispanic'] == True].groupby(['cesd_group_']).agg(['count'])\n",
    "        #reset multiindex\n",
    "        df_row = df_sum.reset_index()\n",
    "        #collapse row indexes to one\n",
    "        df_row.columns = df_row.columns.get_level_values(0)\n",
    "        #get value\n",
    "        lh = []\n",
    "        for value in ['Low','High']:\n",
    "            lh.append(df_row.loc[df_row['cesd_group_'] == value]['hispanic'].values[0])\n",
    "        #percentage\n",
    "        pct_low = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "        pct_high = '%.1f'%(round(lh[1]/total, 4)*100)\n",
    "        #rows\n",
    "        rows.append([\"Hispanic or Latino\",\"(%)\",'%s (%s)'%(lh[0],pct_low),'%s (%s)'%(lh[1],pct_high)])\n",
    "        #race----------------------------------------------------------------------------------------------------------------\n",
    "        df_sum = df_d.groupby(['race','cesd_group_'])['race'].agg(['count'])\n",
    "        #reset multiindex\n",
    "        #df_sum = df_sum.reset_index()\n",
    "        #collapse row indexes to one\n",
    "        #df_sum.columns = df_sum.columns.get_level_values(0)\n",
    "        #transpose \n",
    "        # df_sum.pivot(columns='cesd_group_', values='count')\n",
    "        # #for each race\n",
    "        # for race in ['Low','High']:\n",
    "        #     #get value\n",
    "        #     lh = []\n",
    "        #     for value in ['Low','High']:\n",
    "        #         lh.append(df_row.loc[df_row['cesd_group_'] == value]['hispanic'].values[0])\n",
    "        #     #percentage\n",
    "        #     pct_low = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "        #     pct_high = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "        #     #rows\n",
    "        #     rows.append([\"Race\",\"%s\"%(race), '%s (%s)'%(lh[0],pct_low),'%s (%s)'%(lh[0],pct_high)])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ##--------race ##.sort_index(axis=0)\n",
    "        race = df_d.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'race'].value_counts()\n",
    "        for index, value in race.items():\n",
    "            if value != 0:\n",
    "                above_pct = '%.1f'%(round(value/total, 4)*100)\n",
    "                rows.append([\"Race\",\"%s\"%(index), '%s (%s)'%(value,above_pct),'a'])\n",
    "        del race \n",
    "        \n",
    "        ##--------rrs\n",
    "        rows.append([\"Ruminative Response Scale\",\"(SD)\", \n",
    "                     '%s (%s)'%(str(round(df_dl['rrs_brooding'].mean(),1)), str(round(df_dl['rrs_brooding'].std(),1))),\n",
    "                     '%s (%s)'%(str(round(df_dh['rrs_brooding'].mean(),1)), str(round(df_dh['rrs_brooding'].std(),1)))])\n",
    "    \n",
    "        ##--------CESD\n",
    "        rows.append([\"Center for Epidemiologic Studies Depression Scale\",\"(SD)\", \n",
    "                     '%s (%s)'%(str(round(df_dl['cesd_score'].mean(),1)), str(round(df_dl['cesd_score'].std(),1))),\n",
    "                     '%s (%s)'%(str(round(df_dh['cesd_score'].mean(),1)), str(round(df_dh['cesd_score'].std(),1)))])\n",
    "        ##CESD > 15\n",
    "        # df_sum = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "        # count = df_sum.shape[0]\n",
    "        # above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "        # rows.append(['Center for Epidemiologic Studies Depression Scale', \"CES-D > 15 (%)\", '%s (%s)'%(count,above_pct)])\n",
    "\n",
    "        #----- to df\n",
    "        descriptive = pd.DataFrame(rows)\n",
    "        descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'CESD<=15',3:'CESD>15'})\n",
    "        del descriptive.index.name\n",
    "        \n",
    "        ##create html\n",
    "        html_name = 'demographic'\n",
    "        html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "        title = '<b>Table 1.</b> Participant characteristics (N = %s).'%(total)\n",
    "        footnote = \"<div id='note'>N = Sample size of eyetracking participants. Total participants = %s.\"%(subjects_task)\n",
    "        html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source=\"demographic\", title=title, footnote=footnote)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #breakpoint()\n",
    "        #del df_sum, index, value, above_pct, rows, html_path, title, html, html_name\n",
    "    \n",
    "    is_variables = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------------list of variables\n",
    "    if is_variables:\n",
    "        print(console['red'] + 'Step: list of variables' + console['ENDC'])\n",
    "        df_variables = processing.variables(df=df)\n",
    "        \n",
    "        ##create html\n",
    "        html_name = 'definitions'\n",
    "        html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "        title = '<b>Table 1.</b> Task Variables and Definitions.'\n",
    "        html = plot.html(config=config, df=df_variables, path=html_path, name=html_name, source=\"definitions\", title=title)\n",
    "    \n",
    "    is_descriptive = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------descriptive device\n",
    "    if is_descriptive:\n",
    "        print(console['red'] + 'Step: descriptive device' + console['ENDC'])\n",
    "        rows = []\n",
    "        ##--------os browser gpu type Webcam resolution Webcam message\n",
    "        os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os'].value_counts()\n",
    "        for index, value in os_.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Operating System\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del os_\n",
    "        \n",
    "        # ##--------os_version\n",
    "        os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os_version'].value_counts()\n",
    "        for index, value in os_.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Operating System version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del os_\n",
    "            \n",
    "        ##--------browser\n",
    "        browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser'].value_counts()\n",
    "        for index, value in browser.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Browser\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del browser\n",
    "        \n",
    "        ##--------browser_version\n",
    "        browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser_version'].value_counts()\n",
    "        for index, value in browser.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Browser version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del browser\n",
    "        \n",
    "        ##--------gpu type \n",
    "        gpu_type = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu_type'].value_counts()\n",
    "        for index, value in gpu_type.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"GPU type\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del gpu_type\n",
    "        \n",
    "        ##--------webcam brand\n",
    "        gpu = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu'].value_counts()\n",
    "        for index, value in gpu.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"GPU model\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del gpu\n",
    "        \n",
    "        ##--------devicepixelratio\n",
    "        display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'devicePixelRatio'].value_counts().sort_index(axis=0)\n",
    "        for index, value in display.items():\n",
    "            index = '%.2f'%(round(index, 2))\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"devicePixelRatio\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del display\n",
    "            \n",
    "        ##--------display resolution\n",
    "        display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'monitorSize'].value_counts()\n",
    "        for index, value in display.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Display resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del display\n",
    "        \n",
    "        ##--------webcam message\n",
    "        webcam_m = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'WebcamMessage'].value_counts()\n",
    "        for index, value in webcam_m.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Webcam message\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        \n",
    "        ##--------webcam brand\n",
    "        webcamb = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'webcam_brand'].value_counts()\n",
    "        for index, value in webcamb.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Webcam brand\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del webcamb   \n",
    "        \n",
    "        ##--------Webcam resolution\n",
    "        webcamr = df_s[~df_s['webcamSize'].isin(['.x.'])].drop_duplicates(subset=\"participant\",\n",
    "                       keep=\"first\").loc[:,'webcamSize'].value_counts()\n",
    "        for index, value in webcamr.items():\n",
    "            above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "            rows.append([\"Webcam resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "        del webcamr\n",
    "        \n",
    "        #-------to df\n",
    "        descriptive = pd.DataFrame(rows)\n",
    "        descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})\n",
    "        del descriptive.index.name\n",
    "        \n",
    "        #footnote\n",
    "        footnote = [\n",
    "        '<div class=\"description\">\\n',\n",
    "            'During data collection, participants screen resolution were multiplied by the pixel density ratio, or\\\n",
    "            <a class=\"ref\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio\"><i>devicePixelRatio</i></a>\\\n",
    "            (i.e. width = screen.width / devicePixelRatio = 1920 * 1.5). This was done with the intent of storing true device \\\n",
    "            physical resolution. However to simplify analysis using webgazer, which uses the same initial value \\\n",
    "            to calculate gaze location, participants screen resolution is reverted back to its original value.\\n',\n",
    "        '</div>\\n']\n",
    "        footnote = ''.join(footnote)\n",
    "        \n",
    "        #create html\n",
    "        html_name = 'device'\n",
    "        html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "        title = '<b>Table 1.</b> Device characteristics (N = %s).'%(subjects_task)\n",
    "        html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source=\"device\", title=title, footnote=footnote)\n",
    "        del index, value, above_pct, rows, html_path, title, footnote, html, html_name\n",
    "\n",
    "    is_task = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #--------------------------------------------------------------------------------------------------------descriptive task\n",
    "    if is_task:\n",
    "        print(console['red'] + 'Step: descriptive task' + console['ENDC'])\n",
    "        rows = []\n",
    "        ##--------step\n",
    "        ##----demographic questionnaire\n",
    "        rows.append([\"Pre-Questionnaire\", \"Demographics\", '%s (100.0)'%(subjects_demographics)])\n",
    "        \n",
    "        ##----cesd\n",
    "        pre_ = '%s (%.1f)'%(subjects_cesd, (round(subjects_cesd/subjects_demographics, 4)*100))\n",
    "        rows.append([\"Pre-Questionnaire\", \"CES-D, RRS\", '%s'%(pre_)])\n",
    "        \n",
    "        ##----task\n",
    "        task_ = '%s (%.1f)'%(subjects_task, (round(subjects_task/subjects_demographics, 4)*100))\n",
    "        rows.append([\"Task\", \"Task\", '%s'%(task_)])\n",
    "        ###eyetracking\n",
    "        eye_ = '%s (%.1f)'%(subjects_eyetracking, (round(subjects_eyetracking/subjects_task, 4)*100))\n",
    "        rows.append([\"Task\", \"Eyetracking\", '%s'%(eye_)])\n",
    "        ###eyetracking-used\n",
    "        eyeused_ = '%s (%.1f)'%(subjects_eyetracking_used, (round(subjects_eyetracking_used/subjects_eyetracking, 4)*100))\n",
    "        rows.append([\"Task\", \"Used\", '%s'%(eyeused_)])\n",
    "        ###calibrated\n",
    "        calibrated_ = '%s (%.1f)'%(subjects_calibrated, (round(subjects_calibrated/subjects_eyetracking, 4)*100))\n",
    "        rows.append([\"Task\", \"Calibrated\", '%s'%(calibrated_)])\n",
    "        ###behavioral\n",
    "        behav_ = '%s (%.1f)'%(subjects_behavioral, (round(subjects_behavioral/subjects_task, 4)*100))\n",
    "        rows.append([\"Task\", \"Behavioral\", '%s'%(behav_)])\n",
    "        ###behavioral-used\n",
    "        behavused_ = '%s (%.1f)'%(subjects_behavioral_used, (round(subjects_behavioral_used/subjects_behavioral, 4)*100))\n",
    "        rows.append([\"Task\", \"Used\", '%s'%(behavused_)])\n",
    "        \n",
    "        ##----post assessment\n",
    "        post_ = '%s (%.1f)'%(subjects_mmpi,(round(subjects_mmpi/subjects_demographics, 4)*100))\n",
    "        rows.append([\"Post-Questionnaire\", \"MMPI\", '%s'%(post_)])\n",
    "        \n",
    "        #----to df\n",
    "        descriptive = pd.DataFrame(rows)\n",
    "        descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})\n",
    "        del descriptive.index.name\n",
    "        \n",
    "        #----create html\n",
    "        title = '<b>Table 1.</b> Schedule of Assessments.'\n",
    "        ##footnote\n",
    "        no_webcam = '%s, %s%%'%(webcam_m['NotFoundError'], '%1.f'%(round(webcam_m['NotFoundError']/subjects_task, 5)*100))\n",
    "        blocked_webcam = '%s, %s%%'%(webcam_m['NotAllowedError'], '%1.f'%(round(webcam_m['NotAllowedError']/subjects_task, 5)*100))\n",
    "        footnote = [\n",
    "            '<div class=\"description\">',\n",
    "            'Data were collected from %s to %s. '%(date_start['metadata'],date_end['metadata']),\n",
    "            'Participants unable to meet the eyetracking device requirements (e.g. Chrome and Firefox, webcam, laptop or desktop) ',\n",
    "            'were placed in the behavioral version of dotprobe. Reasons include: participant dropout, ',\n",
    "            'no webcam present on the device (n=%s), '%(no_webcam),\n",
    "            'and blocked access of the webcam by the participants browser (n=%s)'%(blocked_webcam),\n",
    "            '<a class=\"note\" name=\"1\"><sup>1</sup></a>.',\n",
    "            '<br><br>',\n",
    "            'Once completing the <i>Pre-Questionnaire</i> on REDCap, participants are redirected to the task. ',\n",
    "            'Possible reasons for the drop off between <i>Pre-Questionnaire</i> (n=%s) \\\n",
    "            and <i>Task</i> (n=%s) samples can be due to: '%(subjects_cesd, subjects_task),\n",
    "            'Technical error during redirect, and disinterest in continuing to participate in the experiment. ',\n",
    "            '<br><br>',\n",
    "            'Also of note is the amount of participants that were successfully calibrated (n=%s, %1.f%%).'%(subjects_calibrated,\\\n",
    "                            (round(subjects_calibrated/subjects_eyetracking, 4)*100)),\n",
    "            '</div>'\n",
    "        ]\n",
    "        footnote = ''.join(footnote)\n",
    "        \n",
    "        #create html\n",
    "        html_name = 'task'\n",
    "        html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "        html = plot.html(config=config, df=descriptive, path=html_path, source=\"task\", name=html_name, title=title, footnote=footnote)\n",
    "        \n",
    "        del html_name,html_path,no_webcam,blocked_webcam,pre_,task_,calibrated_,behav_,webcam_m,behavused_,eye_,eyeused_,post_,descriptive\n",
    "    \n",
    "    is_summary = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------summary data\n",
    "    if is_summary:\n",
    "        print(console['red'] + 'Step: summary data' + console['ENDC'])\n",
    "        rows = []\n",
    "        #-----------------------------testing group by cesd group (high, low) and trial type mean\n",
    "        df_mean_std = df[['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias','gaze_bias',\n",
    "                       'init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center','mean_gaze_toward',\n",
    "                       'mean_gaze_away','var_gaze_bias','dp_gaze_cor','trialType_',\n",
    "                       'luminance','m_diff_stim','m_diff_dotloc']]\n",
    "        \n",
    "        #------------------------get list of columns\n",
    "        l_var = list(df_mean_std)\n",
    "        l_var_gaze = ['gaze_bias','init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center',\n",
    "                      'mean_gaze_toward','mean_gaze_away','var_gaze_bias']\n",
    "        l_var_dp = ['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias']\n",
    "        \n",
    "        ##--------crate rows\n",
    "        df_mean_std = df_mean_std.groupby(['trialType_']).agg(['mean','std']).T.unstack(level=1)\n",
    "        #collapse headers\n",
    "        df_mean_std.columns = [' '.join(col).strip() for col in df_mean_std.columns.values]\n",
    "        #combine columns\n",
    "        df_mean_std['iaps'] = df_mean_std['iaps mean'].round(4).astype(str) + \" (\" + df_mean_std['iaps std'].round(4).astype(str) + \")\"\n",
    "        df_mean_std['pofa'] = df_mean_std['pofa mean'].round(4).astype(str) + \" (\" + df_mean_std['pofa std'].round(4).astype(str) + \")\"\n",
    "        #reindex and make new column for factor\n",
    "        df_mean_std['variable'] = df_mean_std.index\n",
    "        df_mean_std = df_mean_std.rename({'index': 'variable'}).reset_index(level=0,  drop=True)\n",
    "        #create group column\n",
    "        df_mean_std = df_mean_std.rename({'dp_gaze_corr': 'dpg_core'})\n",
    "        df_mean_std['group'] = pd.np.where(df_mean_std['variable'].str.contains(\"gaze_\"), \"gaze\",\n",
    "                               pd.np.where(df_mean_std['variable'].str.contains(\"dp_\"), \"dotprobe\", \"task\"))\n",
    "        \n",
    "        df_mean_std = df_mean_std[['group','variable','iaps','pofa']]\n",
    "        del df_mean_std.index.name\n",
    "        \n",
    "        #footnote\n",
    "        footnote = [\n",
    "        '<div class=\"description\">',\n",
    "        '</div>\\n'\n",
    "        ]\n",
    "        footnote = ''.join(footnote)\n",
    "        \n",
    "        #create html\n",
    "        html_name = 'summary' \n",
    "        html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "        title = '<b>Table 1.</b> Summary Statistics (N = %s).'%(subjects_used)\n",
    "        html = plot.html(config=config, df=df_mean_std, path=html_path, name=html_name, source=\"summary\", title=title, footnote=footnote)\n",
    "        \n",
    "        del l_var, l_var_gaze, l_var_dp, rows, html_name, html_path, title, footnote, html\n",
    "    \n",
    "    is_plots = False\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #-----------------------------------------------------------------------------------------------------------------exclude\n",
    "    pct_exclude = (round(len(exclude)/len(l_eyetracking), 4)*100)\n",
    "    config['def_exclude'] = \"To reduce the influence of outliers, participants %s were excluded due to 'Dotloc' or 'Stimulus \\\n",
    "    Onset Errors' 3 SD above the median (n=%s, %.1f%%).\"%(exclude, len(exclude), pct_exclude)\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #-------------------------------------------------------------------------------------------------------------------plots\n",
    "    if is_plots:\n",
    "        print(console['red'] + 'Step: plots' + console['ENDC'])\n",
    "        is_single = True\n",
    "        \n",
    "        is_single=True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #------------------------------------------------------------------------------------------------------single subject\n",
    "        if is_single:\n",
    "            \"\"\"\n",
    "            Resources:\n",
    "            - https://media.springernature.com/original/springer-static/image/\n",
    "                art%3A10.3758%2Fs13428-017-0913-7/MediaObjects/13428_2017_913_Figa_HTML.gif\n",
    "            \"\"\"\n",
    "            #-------------------------------------------------single subject bokeh coordinates (all trials)\n",
    "            print(console['red'] + 'Step: bokeh_trial()' + console['ENDC'])\n",
    "            subject = 31\n",
    "            session = 0\n",
    "            #data\n",
    "            path_sns = config['output'] + \"/process/data/eyetracking/%s_%s.csv\"%(subject,session)\n",
    "            df_single = pd.read_csv(path_sns, float_precision='high')\n",
    "            #rename\n",
    "            df_single = df_single.rename(columns={\"LEmotion\":\"left_mood\",\"REmotion\":\"right_mood\"})\n",
    "            #exclude columns\n",
    "            df_single = df_single[['participant','session','subsession','TrialNum','timestamp','trialType','isCongruent',\n",
    "                                    'left_mood','right_mood','monitorSize.px',\n",
    "                                    'x','y','marker','sg_x','sg_y','sg_class',\n",
    "                                    'sg_fix_all','sg_fix_index',\n",
    "                                    'sg_all_bounds','sg_fix_bounds','fix_num',\n",
    "                                    'left_bound','right_bound','dwell']]\n",
    "            \n",
    "            #get rois\n",
    "            stim_bounds, roi_bounds = processing.roi(filters=filters, flt=filters[0][1], df=df_single, manual=True)\n",
    "            #for each subject\n",
    "            flt = 'sg'\n",
    "            for idx in range(198):\n",
    "                #subset data\n",
    "                df_single_ = df_single[df_single['TrialNum'].isin([idx])].reset_index(drop=True)\n",
    "                #draw plot\n",
    "                bokeh_plot = plot.bokeh_trial(config=config, df=df_single_, stim_bounds=stim_bounds, roi_bounds=roi_bounds, flt='sg')\n",
    "                ##get is_congruent\n",
    "                isCongruent = \"congruent\" if df_single_['isCongruent'][0] == True else \"incongruent\"\n",
    "                #html\n",
    "                title = \"(%s) Participant %s, session %s, \"%(isCongruent, subject, session)\n",
    "                html_path = config['output'] + \"/analysis/html/trial/%s_%s_%s.html\"%(subject,session,idx)\n",
    "                html = plot.html(config=config, path=html_path, plots=bokeh_plot, source=\"bokeh\", \n",
    "                                 display=\"trial\", trial=idx, title=title)\n",
    "                                     \n",
    "            del title, path_sns, bokeh_plot, df_single_, html_path, html, subject, session\n",
    "            \n",
    "            #-------------------------------------------------single subject calibration\n",
    "            print(console['green'] + 'bokeh_calibration()' + console['ENDC'])\n",
    "            subject = 'shellie'\n",
    "            monitorSize = [1920,1080]\n",
    "            #for calibration/validation event 0,1,2\n",
    "            for cv_session in range(1,4):\n",
    "                #data\n",
    "                path_sns = config['output'] + \"/analysis/calibration/%s_1_%s_calibration.csv\"%(subject, cv_session)\n",
    "                df_calibration = pd.read_csv(path_sns, float_precision='high')\n",
    "                \n",
    "                #calibration and validation\n",
    "                for event, full in zip(['isCalibrating','isValidating'],['calibration','validation']):\n",
    "                    #subset data\n",
    "                    df_calibration_ = df_calibration.loc[df_calibration['event'] == event].reset_index(drop=True)\n",
    "                    #draw plot\n",
    "                    bokeh_plot = plot.bokeh_calibration(config=config, df=df_calibration_, monitorSize=monitorSize)\n",
    "                    #html\n",
    "                    title = \"Participant %s, event %s,\"%(subject, cv_session)\n",
    "                    html_path = config['output'] + \"/analysis/html/cv/%s_%s_%s.html\"%(subject, cv_session, full)\n",
    "                    html = plot.html(config=config, path=html_path, plots=bokeh_plot, source=\"bokeh\", display=\"calibration\",\n",
    "                                         trial=full, session=cv_session, title=title)\n",
    "                                 \n",
    "            del title, path_sns, bokeh_plot, html_path, html\n",
    "\n",
    "        is_density = True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #--------------------------------------------------------------------------------------------------------density plot\n",
    "        if is_density:\n",
    "            print(console['red'] + 'Step: density_plot()' + console['ENDC'])\n",
    "            #Computes and draws density plot (kernel density estimate), which is a smoothed version of the histogram. \n",
    "            #This is used as a gage for normality\n",
    "            df_density = df[['participant','trialType_','m_rt',\n",
    "                             'm_diff_dotloc','m_diff_stim','luminance',\n",
    "                             'rrs_brooding','cesd_score','cesd_group_',\n",
    "                             'dp_bias','n_dp_valid','gaze_bias','n_gaze_valid',\n",
    "                             'var_gaze_bias','final_gaze_bias']].loc[df['nested'] == 'subject']   \n",
    "            \n",
    "            #----exclude\n",
    "            df_density = df_density[~df_density['participant'].isin(exclude)]   \n",
    "            \n",
    "            #file\n",
    "            title = string.capwords('kernel density estimate')\n",
    "            \n",
    "            #create images\n",
    "            density, html_plots = plot.density_plot(config=config, df=df_density, title=title)\n",
    "            #description of plots\n",
    "            intro = \"The kernel density estimate (kde) is used here as a quick check of normality for each of the variables of \\\n",
    "            interest in the model. All data here has been nested by subject. %s\"%(config['def_exclude'])\n",
    "            #create html\n",
    "            html_path = config['output'] + \"/analysis/html/density.html\"\n",
    "            html = plot.html(config=config, path=html_path, plots=html_plots, source=\"plots\", intro=intro)\n",
    "            del density, intro, html_plots, html_path, html, title\n",
    "            \n",
    "        is_corr = True \n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #--------------------------------------------------------------------------------------------------correlation matrix\n",
    "        if is_corr:\n",
    "            print(console['red'] + 'Step: corr_matrix()' + console['ENDC'])\n",
    "            #run correlation matrix\n",
    "            df_corr = df[['dp_bias','n_dp_valid','var_dp_bias',\n",
    "                          'gaze_bias','n_gaze_valid','var_gaze_bias','final_gaze_bias',\n",
    "                          'rrs_brooding','cesd_score',\n",
    "                          'm_rt','m_diff_dotloc','m_diff_stim',\n",
    "                          'luminance']].loc[df['nested'] == 'subject']\n",
    "            \n",
    "            #file\n",
    "            file = 'corr_matrix'\n",
    "            method = 'spearman'\n",
    "            title = string.capwords('%s correlation coefficient matrix (p-value).'%(method))\n",
    "            \n",
    "            path = config['output'] + \"/analysis/html/%s.html\"%(file)\n",
    "            corr_matrix = plot.corr_matrix(config=config, df=df_corr, path=path, title=title, method=method)\n",
    "            del path, corr_matrix\n",
    "                \n",
    "            del file, title, method\n",
    "        \n",
    "        is_boxplot = True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #-------------------------------------------------------------------------------------------------------------boxplot\n",
    "        if is_boxplot:\n",
    "            print(console['red'] + 'Step: boxplot()' + console['ENDC'])\n",
    "            #----create temp df\n",
    "            df_box = df[['dp_bias','gaze_bias','dp_gaze_cor','final_gaze_bias','participant','trialType_','cesd_group_','nested']]\n",
    "            html_plots = []\n",
    "\n",
    "            #----exclude\n",
    "            df_box = df_box[~df_box['participant'].isin(exclude)]\n",
    "            df_box_error = df_error[~df_error['participant'].isin(exclude)]\n",
    "            \n",
    "            #analysis--------------------------------------------------------------------------------------------------------\n",
    "            html_file = 'bias_boxplot'\n",
    "            y=['dp_bias','gaze_bias','dp_gaze_cor','final_gaze_bias']\n",
    "            #create plot\n",
    "            intro = 'This was done with two purposes. \\\n",
    "                    1) To get general trends in the data. \\\n",
    "                    2) To identify potential outliers in the data that might warrent investigation. Participants that \\\n",
    "                    may need follow up are 999999, 111111, 314, 298, 256, 206, 218, 201, 193, 183, 140, 84, 60, 12. \\\n",
    "                    Note: All data here has either been collapsed by subject or trialType.'\n",
    "            ##-------cesd\n",
    "            df_box_ = df_box.loc[df['nested'] == 'subject']\n",
    "            file = 'boxplot_cesd'\n",
    "            x='cesd_group_'\n",
    "            cat='analysis'\n",
    "            title = 'Boxplots, CES-D Cutoff (N = %s, collapsed by subject)'%(subjects_used) \n",
    "            footnote = \"Data collapsed by subject:trialType. %s\"%(config['def_exclude'])\n",
    "            sns_path = config['output'] + \"/analysis/html/img/%s.png\"%(file)\n",
    "            plot.boxplot(config=config, df=df_box_, path=sns_path, x=x,y=y, cat=cat)\n",
    "            html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n",
    "            \n",
    "            ##-------trialType\n",
    "            df_box_ = df_box.loc[df['nested'] == 'trialType']\n",
    "            file = 'boxplot_trial'\n",
    "            x='trialType_'\n",
    "            cat='analysis'\n",
    "            title = 'Boxplots, Trial Type (N = %s, collapsed by subject:trialType)'%(subjects_used)\n",
    "            footnote = \"Data collapsed by subject:trialType. %s\"%(config['def_exclude'])\n",
    "            sns_path = config['output'] + \"/analysis/html/img/%s.png\"%(file)\n",
    "            plot.boxplot(config=config, df=df_box_, path=sns_path, x=x, y=y, cat=cat)\n",
    "            html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n",
    "            \n",
    "            #save folders\n",
    "            html_path = config['output'] + \"/analysis/html/%s.html\"%(html_file)\n",
    "            html = plot.html(config=config, path=html_path, plots=html_plots, source=\"plots\", display=\"boxplot\", intro=intro)\n",
    "            del intro, html_file, file, title, sns_path, html_path, html, cat, x, y\n",
    "         \n",
    "            #timing----------------------------------------------------------------------------------------------------------\n",
    "            html_plots = []\n",
    "            html_file = 'rt_boxplot'\n",
    "            x = ['race','gender','is_normalvision','os']\n",
    "            cat = 'demographics'\n",
    "            \n",
    "            ##-------response time\n",
    "            y = 'Key_Resp_rt'\n",
    "            intro = 'This was done to compare differences in response time between os, webcamsize, gender, race and other factors.'\n",
    "            footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n",
    "            races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s\"%(config['def_exclude'])\n",
    "            #create plot\n",
    "            file = 'rt_boxplot'\n",
    "            title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n",
    "            sns_path = config['output'] + \"/analysis/html/img/%s.png\"%(file)\n",
    "            plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x, y=y, cat=cat)\n",
    "            html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n",
    "            \n",
    "            ##-------diff_dotloc\n",
    "            y = 'diff_dotloc'\n",
    "            intro = 'This was done to compare differences between expected and true dotloc onset between os, webcamsize, \\\n",
    "            gender, race and other factors.'\n",
    "            footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n",
    "            races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s\"%(config['def_exclude'])\n",
    "            #create plot\n",
    "            file = 'dotloc_boxplot'\n",
    "            title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n",
    "            sns_path = config['output'] + \"/analysis/html/img/%s.png\"%(file)\n",
    "            plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x,y=y, cat=cat)\n",
    "            html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n",
    "            \n",
    "            ##-------diff_stim\n",
    "            y = 'diff_stim'\n",
    "            intro = 'This was done to compare differences between expected and true stim onset between os, webcamsize, \\\n",
    "            gender, race and other factors.'\n",
    "            footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n",
    "            races', 'Black or African American', 'None of the above' were excluded here for displaying purposes. %s\"%(config['def_exclude'])\n",
    "            #create plot\n",
    "            file = 'stim_boxplot'\n",
    "            title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n",
    "            sns_path = config['output'] + \"/analysis/html/img/%s.png\"%(file)\n",
    "            plot.boxplot(config=config, df=df_box_error, path=sns_path, x=x,y=y, cat=cat)\n",
    "            html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n",
    "            \n",
    "            #-------save folders\n",
    "            html_path = config['output'] + \"/analysis/html/%s.html\"%(html_file)\n",
    "            html = plot.html(config=config, path=html_path, plots=html_plots, source=\"plots\", display=\"boxplot\", intro=intro)\n",
    "            del intro, html_file, file, title, html_path, html, cat, x, y, footnote\n",
    "            \n",
    "    is_analysis = True\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------------------analysis\n",
    "    if is_analysis:\n",
    "        print(console['red'] + 'Step: analysis' + console['ENDC'])\n",
    "\n",
    "        \"\"\"\n",
    "        Resources:\n",
    "        - https://stats.idre.ucla.edu/other/mult-pkg/whatstat/\n",
    "        \"\"\"\n",
    "        \n",
    "        is_dwell = True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #---------------------------------------------------------------------------------------------------ANOVA: dwell time\n",
    "        if is_dwell:\n",
    "            print(console['red'] + 'Step: ANOVA (dwell time)' + console['ENDC'])\n",
    "            #mixed model anova\n",
    "            \"\"\"\n",
    "            Resources:\n",
    "            - https://m-clark.github.io/docs/mixedModels/anovamixed.html\n",
    "            - http://dwoll.de/rexrepos/posts/anovaMixed.html\n",
    "            - https://rpsychologist.com/r-guide-longitudinal-lme-lmer\n",
    "            - https://stats.stackexchange.com/questions/247582/repeated-measures-anova-in-r-errorsubject-vs-errorsubject-day\n",
    "            - https://cran.r-project.org/web/packages/afex/vignettes/afex_anova_example.html#post-hoc-contrasts-and-plotting\n",
    "            - http://www.let.rug.nl/nerbonne/teach/rema-stats-meth-seminar/presentations/Wieling-MixedModels-2011.pdf\n",
    "            \"\"\"\n",
    "            #-----parameters\n",
    "            y = 'dwell_time'\n",
    "            f = '''%s ~ cesd_group * aoi + trialType + (1|participant)'''%(y)\n",
    "            \n",
    "            #----save data for access by R and for calculating dwell time\n",
    "            csv = \"dwell_data.csv\"\n",
    "            path = config['output'] + \"/analysis/html/model/anova/\"\n",
    "        \n",
    "\t\t\t#-----calculate dwell time using multiprocessing\n",
    "\t\t\t# use __name__ to protect main module\n",
    "            df_dwell, error_dwell = processing.dwell(df=df, cores=7) if __name__ == '__main__' else None\n",
    "        \n",
    "            #----normalize dwell_time for comparison between iaps and pofa\n",
    "            df_dwell['dwell_time'] = df_dwell.apply(lambda x: (x['dwell_time']/4500) \n",
    "            if (x['trialType'] == 'iaps') else (x['dwell_time']/3000), axis=1)\n",
    "            \n",
    "\t\t\t#-----exclude participants, group by subject:trialType:aoi\n",
    "            # exclude participants\n",
    "            df_dwell = df_dwell[~df_dwell['participant'].isin(exclude)]\n",
    "            # groupby\n",
    "            df_dwell = df_dwell.groupby(['participant','cesd_group','trialType','aoi'])['dwell_time'].mean().reset_index()\n",
    "\n",
    "\t\t\t#-----run\n",
    "            lmer_, lmer_result, lmer_r = model.anova(config=config, df=df_dwell, y=y, f=f, csv=csv, path=path)\n",
    "        \n",
    "        is_diff = True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #---------------------------------------------------Negative-Binomial Poisson Regression: stimulus/dotloc onset error\n",
    "        if is_diff:\n",
    "            print(console['red'] + 'Step: Poisson Regression' + console['ENDC'])\n",
    "            \n",
    "            #-----parameters\n",
    "            y = ['diff_stim','diff_dotloc'] #build models for each item in list\n",
    "            #create function for each response variable\n",
    "            for _y in y:\n",
    "                #-----path\n",
    "                path = config['output'] + \"/analysis/html/model/nb/\"\n",
    "                #-----formula\n",
    "                f = \"%s ~ os + race + gender + trialType + TrialNum_ + (1|participant) + (TrialNum_|participant)\"%(_y)\n",
    "                #-----run\n",
    "                nb_, nb_result, nb_r = model.glmer_nb(config=config, df=df_error, y=_y, f=f, exclude=exclude, csv=csv, path=path)\n",
    "        \n",
    "        is_mixed = True\n",
    "        #%%------------------------------------------------------------------------------------------------------------------\n",
    "        #-------------------------------------------------generalized linear mixed-effects logistic model with random effects\n",
    "        if is_mixed:\n",
    "            print(console['red'] + 'Step: Logistic Regression' + console['ENDC'])\n",
    "            \n",
    "            #-----exclude participants, group by subject\n",
    "            # exclude participants\n",
    "            df_ = df[~df['participant'].isin(exclude)]\n",
    "            # merge datasets to allow trial-level analysis\n",
    "            merge = ['participant','cesd_group','dp_bias','gaze_bias','n_dp_valid','n_gaze_valid','nested']\n",
    "            df_1 = df_error.merge((df_[merge].drop_duplicates(subset=\"participant\", keep=\"first\")), on='participant')\n",
    "            # keep relevant columns only\n",
    "            df_1 = df_1[['participant','race','os','TrialNum_','cesd_group','dp_bias','m_rt','trialType','gaze_bias',\n",
    "                         'n_dp_valid','n_gaze_valid','nested']]\n",
    "            # groupby\n",
    "            df_1 = df_1.loc[df_1['nested'] == 'subject']\n",
    "            \n",
    "            #-----parameters\n",
    "            #save data for access by R\n",
    "            csv = \"logit.csv\"\n",
    "            y = 'cesd_group' \n",
    "            #build models for each iv and corresponding weight in list\n",
    "            x = ['dp_bias','gaze_bias']\n",
    "            weights = ['n_dp_valid','n_gaze_valid']\n",
    "            #create function for each IV\n",
    "            for _x, _w in zip(x, weights):\n",
    "                #-----path\n",
    "                path = config['output'] + \"/analysis/html/model/logit/%s\"%(_x)\n",
    "                #-----formula\n",
    "                f=\"cesd_group ~ trialType + %s*TrialNum_ + (1+TrialNum_|participant), weights=%s\"%(_x, _w)\n",
    "                #-----run\n",
    "                log_, log_result, log_r = model.logistic(config=config, df=df_1, y=y, f=f, exclude=exclude, csv=csv, path=path)\n",
    "    \n",
    "\n",
    "    #%%----------------------------------------------------------------------------------------------------------------------\n",
    "    #----------------------------------------------------------------------------------------------------------------finished\n",
    "    #---------------------------------------------------------------------------------------------------------garbage collect\n",
    "    gc.collect()\n",
    "    #---------------------------------------------------------------------------------------------------------quick functions\n",
    "    #get list of columns\n",
    "    #lst = list(df)\n",
    "    #install pip package\n",
    "    #from pip._internal import main as _main\n",
    "    #_main(['install','statsmodels'])\n",
    "    \n",
    "    #----------------------------------------------------------------------------------------------------------iPython Magics\n",
    "    #%matplotlib qt5\n",
    "    #%matplotlib tk\n",
    "    #%matplotlib inline\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------other magics\n",
    "    #from pdb import set_trace as breakpoint\n",
    "    #breakpoint()\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------profile code\n",
    "    ##method 1 -- use within iPython interpreter\n",
    "    #%load_ext snakeviz\n",
    "    #%snakeviz runfile('C:/Users/sr38553/projects/work/eyelink_webgazer/py/run.py', \n",
    "    #wdir='C:/Users/sr38553/projects/work/eyelink_webgazer/py')\n",
    "    \n",
    "    ##method 2\n",
    "    #from pycallgraph import PyCallGraph\n",
    "    #from pycallgraph.output import GraphvizOutput\n",
    "    #with PyCallGraph(output=GraphvizOutput()):\n",
    "    #    df_all, cgxy_df, fgxy_df, trial = processing.run()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
