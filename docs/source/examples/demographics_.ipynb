{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. _demographics:\n",
    " \n",
    ".. title:: Demographics\n",
    "\n",
    "#### Demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span>Created on Sat May 1 15:12:38 2019</span>  \n",
    " <span>@author: 'Semeon Risom'</span>  \n",
    " <span>@email: 'semeon.risom@gmail.com'</span>  \n",
    " <span>@url: 'https://semeon.io/d/R33-analysis'</span>  \n",
    " <span>@purpose: Process Demographic Data.</span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----local\n",
    "from mdl import plot, processing, raw, redcap\n",
    "import mdl.model as model\n",
    "import mdl.settings as settings\n",
    "\n",
    "#----check if required libraries are available\n",
    "is_library = False\n",
    "if is_library:\n",
    "    settings.library()\n",
    "pass\n",
    "#----core\n",
    "from pdb import set_trace as breakpoint\n",
    "import pandas as pd\n",
    "import gc, glob, string, pytz\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### initalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing = processing(config, filters)\n",
    "console = settings.console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'processing metadata' + console['ENDC'])\n",
    "#file path\n",
    "fpath = config['output'] + \"/raw/\" + config['task']\n",
    "#save path\n",
    "spath = config['output'] + \"/analysis/subject_metadata.csv\"\n",
    "subject_metadata = processing.subject_metadata(fpath=fpath, spath=spath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude participants\n",
    "exclude = [999999, 111111]\n",
    "print(console['red'] + 'preparing data: %s'%(exclude) + console['ENDC'])\n",
    "\n",
    "#read demographics and rename id=\"participant\"\n",
    "p_demo = config['output'] + \"/analysis/demographics.csv\"\n",
    "df_demographics = pd.read_csv(p_demo, float_precision='high')\n",
    "##exclude participants\n",
    "df_demographics = df_demographics[~df_demographics['participant'].isin(exclude)]\n",
    "#create gender column\n",
    "df_demographics['gender'] = df_demographics.apply(lambda x: 'female' if (x['female'] == 1 and x['male'] == 0) else \n",
    "                                                  ('male' if (x['male'] == 1 and x['female'] == 0) else 'other'), axis=1)\n",
    "#replace eye color\n",
    "color=['Light Gray','Gray','Light Blue','Blue','Violet','Blue-Green','Green','Amber','Hazel',\n",
    "'Light Brown','Dark Brown','Black', 'Other']\n",
    "df_demographics['eye_color'] = df_demographics['eye_color'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], color)\n",
    "\n",
    "##-------read cesd and rename id=\"participant\"\n",
    "p_cesd = config['output'] + \"/analysis/cesd_rrs.csv\"\n",
    "df_cesd = pd.read_csv(p_cesd, float_precision='high')\n",
    "df_cesd = df_cesd.rename(columns={'record_id':'participant'})\n",
    "##group cesd scores #bionomial\n",
    "df_cesd['cesd_group'] = df_cesd.apply(lambda x: 1 if (x['cesd_score'] > 15) else 0, axis=1)\n",
    "df_cesd['cesd_group_'] = df_cesd.apply(lambda x: 'High' if (x['cesd_score'] > 15) else 'Low', axis=1)\n",
    "##exclude participants\n",
    "df_cesd = df_cesd[~df_cesd['participant'].isin(exclude)]\n",
    "\n",
    "##-------read mmpi\n",
    "p_mmpi = config['output'] + \"/analysis/mmpi.csv\"\n",
    "df_mmpi = pd.read_csv(p_mmpi, float_precision='high')\n",
    "df_mmpi = df_mmpi.rename(columns={'record_id':'participant'})\n",
    "##exclude participants\n",
    "df_mmpi = df_mmpi[~df_mmpi['participant'].isin(exclude)]\n",
    "\n",
    "##-------read subject metadata\n",
    "p_subject = config['output'] + \"/analysis/subject_metadata.csv\"\n",
    "df_metadata = pd.read_csv(p_subject, float_precision='high')\n",
    "##drop duplicate participant listings\n",
    "df_metadata = df_metadata.drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "#start and end dates\n",
    "date_start.append({'metadata':'%s'%(df_metadata['date'].min())})\n",
    "date_end.append({'metadata':'%s'%(df_metadata['date'].max())})\n",
    "##exclude participants\n",
    "df_metadata = df_metadata[~df_metadata['participant'].isin(exclude)]\n",
    "#r#ename variables\n",
    "df_metadata = df_metadata.rename(columns={\"isWindowSuccess\": \"is_calibrated\"})\n",
    "\n",
    "##-------read bias summary and rename id=\"participant\"\n",
    "#if eyetracking\n",
    "if config['type'] == 'eyetracking': p_bias = config['output'] + \"/bias/eyetracking_bias.csv\"\n",
    "#if behavioral\n",
    "else: p_bias = config['output'] + \"/bias/behavioral_bias.csv\"\n",
    "\n",
    "#load\n",
    "df_bias = pd.read_csv(p_bias, float_precision='high')\n",
    "df_bias = df_bias.rename(columns={'id':'participant'})\n",
    "###drop unusual data\n",
    "df_bias = df_bias.drop(df_bias[(df_bias['trialType'].isnull())].index)\n",
    "##set dp_bias and gaze_bias as float\n",
    "df_bias['dp_bias'] = df_bias['dp_bias'].astype(float)\n",
    "if config['type'] == 'eyetracking': df_bias['gaze_bias'] = df_bias['gaze_bias'].astype(float)\n",
    "\n",
    "#set trialtype as text\n",
    "df_bias['trialType_'] = df_bias['trialType']\n",
    "df_bias['trialType'] = df_bias.apply(lambda x: 1 if (x['trialType'] == 'pofa') else 0, axis=1)\n",
    "##exclude participants\n",
    "df_bias = df_bias[~df_bias['participant'].isin(exclude)]\n",
    "\n",
    "##-------getting demographic data\n",
    "df_s = df_metadata.merge(df_cesd,on='participant').merge(df_demographics,on='participant')\n",
    "\n",
    "##-------merge\n",
    "df = df_bias.merge(df_cesd,on='participant').merge(df_metadata,on='participant').merge(df_demographics,on='participant')\n",
    "#exclude participants\n",
    "df = df[~df['participant'].isin(exclude)]\n",
    "#rename columns\n",
    "##rename microsoft os to msos, mac os to macos\n",
    "df['os'].replace(['Microsoft Windows', 'macOS','Chrome OS'], ['msos', 'macos', 'cos'], inplace=True)\n",
    "\n",
    "##-------calculate difference between real stimulus, dotloc onset and real value #then merge medians with df\n",
    "merge = ['race','gender','is_normalvision','os','participant']\n",
    "df_error, onset_error, drop = processing.onset_diff(df0=df, merge=merge, cores=7)\n",
    "##combine exclude lists\n",
    "exclude = drop + exclude\n",
    "\n",
    "##-------final version of df\n",
    "#merge\n",
    "df = pd.merge(df, df_error[['TrialNum_','m_rt','accuracy','m_diff_dotloc','m_diff_stim','participant']]              .drop_duplicates(subset=\"participant\", keep=\"first\"), how='left', on='participant')\n",
    "\n",
    "##export for seperate analysis in r\n",
    "csv_path = config['output'] + \"/analysis/final_data.csv\"\n",
    "print(console['red'] + 'Step: export for R analysis: %s'%(csv_path) + console['ENDC'])\n",
    "df.to_csv(csv_path, index=None)        \n",
    "\n",
    "##--------number of subjects\n",
    "##demographics\n",
    "subjects_demographics = df_demographics.shape[0]\n",
    "###task\n",
    "subjects_task = df_metadata.shape[0]\n",
    "###eyetracking\n",
    "subjects_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True].shape[0]\n",
    "l_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True]['participant'].astype('int').to_list()\n",
    "###eyetracking\n",
    "subjects_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True].shape[0]\n",
    "l_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True]['participant'].astype('int').to_list()\n",
    "###behavioral\n",
    "subjects_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False].shape[0]\n",
    "l_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False]['participant'].astype('int').to_list()\n",
    "##cesd\n",
    "subjects_cesd = df_cesd.shape[0]\n",
    "##cesd\n",
    "subjects_mmpi = df_mmpi.shape[0]\n",
    "\n",
    "###get actual participants used in analysis\n",
    "subjects_eyetracking_used = len(glob.glob(config['output'] + \"/tlbs/eyetracking/*.csv\"))\n",
    "subjects_behavioral_used = len(glob.glob(config['output'] + \"/tlbs/behavioral/*.csv\"))\n",
    "\n",
    "##get subjects used\n",
    "if config['type'] == 'eyetracking':\n",
    "    subjects_used = subjects_eyetracking_used\n",
    "else:\n",
    "    subjects_used = subjects_behavioral_used\n",
    "\n",
    "##--------date\n",
    "date_start = dict((key,d[key]) for d in date_start for key in d)\n",
    "date_end = dict((key,d[key]) for d in date_end for key in d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### demographic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------get max, min values\n",
    "#drop non-eyetracking participants\n",
    "df_d = df_s[df_s['participant'].isin(l_eyetracking)]\n",
    "#cesd high\n",
    "df_dh = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n",
    "#cesd low\n",
    "df_dl = df_d.loc[df_d['cesd_score'] <= 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n",
    "\n",
    "#get total used\n",
    "total = len(l_eyetracking)\n",
    "\n",
    "#-----------------------------descriptive demographic stats\n",
    "print(console['red'] + 'Step: descriptive demographic' + console['ENDC'])\n",
    "rows = []\n",
    "##--------age\n",
    "rows.append([\"Age\",\"mean (SD)\", \n",
    "             '%s (%s)'%(str(round(df_dl['age'].mean(),1)),str(round(df_dl['age'].std(),1))),\n",
    "             '%s (%s)'%(str(round(df_dh['age'].mean(),1)),str(round(df_dh['age'].std(),1)))])\n",
    "\n",
    "##--------race ##.sort_index(axis=0)\n",
    "eyecolor_ = df_d.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'eye_color'].value_counts()\n",
    "for index, value in eyecolor_.items():\n",
    "    if value != 0:\n",
    "        above_pct = '%.1f'%(round(value/total, 4)*100)\n",
    "        rows.append([\"Eye Color\",\"%s\"%(index), '%s (%s)'%(value,above_pct),''])\n",
    "del eyecolor_\n",
    "\n",
    "##--------vision\n",
    "#normal\n",
    "df_sum = df_d.loc[df_d['is_normalvision'] == True].drop_duplicates(subset=\"participant\",keep=\"first\").reset_index(drop=True)\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "rows.append([\"Vision\", \"Normal\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "#corrective\n",
    "df_sum = df_d.loc[df_d['is_corrective'] == True].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "rows.append([\"Vision\", \"Corrective\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "##--------handedness-right\n",
    "df_sum = df_d.loc[df_d['handedness'] == 'Right'].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "rows.append([\"Handedness (Right)\",\"Right\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "##--------gender\n",
    "##female\n",
    "df_sum = df_d.loc[df_d['female'] == 1].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "rows.append([\"Gender\",\"Female\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "##male\n",
    "df_sum = df_d.loc[df_d['male'] == 1].drop_duplicates(subset=\"participant\",keep=\"first\").reset_index(drop=True)\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "rows.append([\"Gender\",\"Male\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "##--------        \n",
    "df_sum = df_d.loc[df_d['hispanic'] == True].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "df_d.groupby(['hispanic']).agg(['mean', 'count'])\n",
    "count = df_sum.shape[0]\n",
    "above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "#rows.append([\"Hispanic or Latino\",\"(%)\", '%s (%s)'%(count,above_pct),'a'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#hispanic/latino-----------------------------------------------------------------------------------------------------\n",
    "df_sum = df_d[['hispanic','cesd_group_']].loc[df_d['hispanic'] == True].groupby(['cesd_group_']).agg(['count'])\n",
    "#reset multiindex\n",
    "df_row = df_sum.reset_index()\n",
    "#collapse row indexes to one\n",
    "df_row.columns = df_row.columns.get_level_values(0)\n",
    "#get value\n",
    "lh = []\n",
    "for value in ['Low','High']:\n",
    "    lh.append(df_row.loc[df_row['cesd_group_'] == value]['hispanic'].values[0])\n",
    "#percentage\n",
    "pct_low = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "pct_high = '%.1f'%(round(lh[1]/total, 4)*100)\n",
    "#rows\n",
    "rows.append([\"Hispanic or Latino\",\"(%)\",'%s (%s)'%(lh[0],pct_low),'%s (%s)'%(lh[1],pct_high)])\n",
    "#race----------------------------------------------------------------------------------------------------------------\n",
    "df_sum = df_d.groupby(['race','cesd_group_'])['race'].agg(['count'])\n",
    "#reset multiindex\n",
    "#df_sum = df_sum.reset_index()\n",
    "#collapse row indexes to one\n",
    "#df_sum.columns = df_sum.columns.get_level_values(0)\n",
    "#transpose \n",
    "# df_sum.pivot(columns='cesd_group_', values='count')\n",
    "# #for each race\n",
    "# for race in ['Low','High']:\n",
    "#     #get value\n",
    "#     lh = []\n",
    "#     for value in ['Low','High']:\n",
    "#         lh.append(df_row.loc[df_row['cesd_group_'] == value]['hispanic'].values[0])\n",
    "#     #percentage\n",
    "#     pct_low = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "#     pct_high = '%.1f'%(round(lh[0]/total, 4)*100)\n",
    "#     #rows\n",
    "#     rows.append([\"Race\",\"%s\"%(race), '%s (%s)'%(lh[0],pct_low),'%s (%s)'%(lh[0],pct_high)])\n",
    "\n",
    "##--------race ##.sort_index(axis=0)\n",
    "race = df_d.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'race'].value_counts()\n",
    "for index, value in race.items():\n",
    "    if value != 0:\n",
    "        above_pct = '%.1f'%(round(value/total, 4)*100)\n",
    "        rows.append([\"Race\",\"%s\"%(index), '%s (%s)'%(value,above_pct),'a'])\n",
    "del race \n",
    "\n",
    "##--------rrs\n",
    "rows.append([\"Ruminative Response Scale\",\"(SD)\", \n",
    "             '%s (%s)'%(str(round(df_dl['rrs_brooding'].mean(),1)), str(round(df_dl['rrs_brooding'].std(),1))),\n",
    "             '%s (%s)'%(str(round(df_dh['rrs_brooding'].mean(),1)), str(round(df_dh['rrs_brooding'].std(),1)))])\n",
    "\n",
    "##--------CESD\n",
    "rows.append([\"Center for Epidemiologic Studies Depression Scale\",\"(SD)\", \n",
    "             '%s (%s)'%(str(round(df_dl['cesd_score'].mean(),1)), str(round(df_dl['cesd_score'].std(),1))),\n",
    "             '%s (%s)'%(str(round(df_dh['cesd_score'].mean(),1)), str(round(df_dh['cesd_score'].std(),1)))])\n",
    "##CESD > 15\n",
    "# df_sum = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n",
    "# count = df_sum.shape[0]\n",
    "# above_pct = '%.1f'%(round(df_sum.shape[0]/total, 4)*100)\n",
    "# rows.append(['Center for Epidemiologic Studies Depression Scale', \"CES-D > 15 (%)\", '%s (%s)'%(count,above_pct)])\n",
    "\n",
    "#----- to df\n",
    "descriptive = pd.DataFrame(rows)\n",
    "descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'CESD<=15',3:'CESD>15'})\n",
    "del descriptive.index.name\n",
    "\n",
    "##create html\n",
    "html_name = 'demographic'\n",
    "html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "title = '<b>Table 1.</b> Participant characteristics (N = %s).'%(total)\n",
    "footnote = \"<div id='note'>N = Sample size of eyetracking participants. Total participants = %s.\"%(subjects_task)\n",
    "html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source=\"demographic\", title=title, footnote=footnote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### list of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'Step: list of variables' + console['ENDC'])\n",
    "df_variables = processing.variables(df=df)\n",
    "\n",
    "##create html\n",
    "html_name = 'definitions'\n",
    "html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "title = '<b>Table 1.</b> Task Variables and Definitions.'\n",
    "html = plot.html(config=config, df=df_variables, path=html_path, name=html_name, source=\"definitions\", title=title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### descriptive device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'Step: descriptive device' + console['ENDC'])\n",
    "rows = []\n",
    "##--------os browser gpu type Webcam resolution Webcam message\n",
    "os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os'].value_counts()\n",
    "for index, value in os_.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Operating System\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del os_\n",
    "\n",
    "# ##--------os_version\n",
    "os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os_version'].value_counts()\n",
    "for index, value in os_.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Operating System version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del os_\n",
    "\n",
    "##--------browser\n",
    "browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser'].value_counts()\n",
    "for index, value in browser.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Browser\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del browser\n",
    "\n",
    "##--------browser_version\n",
    "browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser_version'].value_counts()\n",
    "for index, value in browser.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Browser version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del browser\n",
    "\n",
    "##--------gpu type \n",
    "gpu_type = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu_type'].value_counts()\n",
    "for index, value in gpu_type.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"GPU type\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del gpu_type\n",
    "\n",
    "##--------webcam brand\n",
    "gpu = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu'].value_counts()\n",
    "for index, value in gpu.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"GPU model\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del gpu\n",
    "\n",
    "##--------devicepixelratio\n",
    "display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'devicePixelRatio'].value_counts().sort_index(axis=0)\n",
    "for index, value in display.items():\n",
    "    index = '%.2f'%(round(index, 2))\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"devicePixelRatio\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del display\n",
    "\n",
    "##--------display resolution\n",
    "display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'monitorSize'].value_counts()\n",
    "for index, value in display.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Display resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del display\n",
    "\n",
    "##--------webcam message\n",
    "webcam_m = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'WebcamMessage'].value_counts()\n",
    "for index, value in webcam_m.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Webcam message\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "\n",
    "##--------webcam brand\n",
    "webcamb = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'webcam_brand'].value_counts()\n",
    "for index, value in webcamb.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Webcam brand\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del webcamb   \n",
    "\n",
    "##--------Webcam resolution\n",
    "webcamr = df_s[~df_s['webcamSize'].isin(['.x.'])].drop_duplicates(subset=\"participant\",\n",
    "               keep=\"first\").loc[:,'webcamSize'].value_counts()\n",
    "for index, value in webcamr.items():\n",
    "    above_pct = '%.1f'%(round(value/subjects_task, 4)*100)\n",
    "    rows.append([\"Webcam resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n",
    "del webcamr\n",
    "\n",
    "#-------to df\n",
    "descriptive = pd.DataFrame(rows)\n",
    "descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})\n",
    "del descriptive.index.name\n",
    "\n",
    "#footnote\n",
    "footnote = [\n",
    "'<div class=\"description\">\\n',\n",
    "    'During data collection, participants screen resolution were multiplied by the pixel density ratio, or\\\n",
    "    <a class=\"ref\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio\"><i>devicePixelRatio</i></a>\\\n",
    "    (i.e. width = screen.width / devicePixelRatio = 1920 * 1.5). This was done with the intent of storing true device \\\n",
    "    physical resolution. However to simplify analysis using webgazer, which uses the same initial value \\\n",
    "    to calculate gaze location, participants screen resolution is reverted back to its original value.\\n',\n",
    "'</div>\\n']\n",
    "footnote = ''.join(footnote)\n",
    "\n",
    "#create html\n",
    "html_name = 'device'\n",
    "html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "title = '<b>Table 1.</b> Device characteristics (N = %s).'%(subjects_task)\n",
    "html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source=\"device\", title=title, footnote=footnote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### descriptive task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'Step: descriptive task' + console['ENDC'])\n",
    "rows = []\n",
    "##--------step\n",
    "##----demographic questionnaire\n",
    "rows.append([\"Pre-Questionnaire\", \"Demographics\", '%s (100.0)'%(subjects_demographics)])\n",
    "\n",
    "##----cesd\n",
    "pre_ = '%s (%.1f)'%(subjects_cesd, (round(subjects_cesd/subjects_demographics, 4)*100))\n",
    "rows.append([\"Pre-Questionnaire\", \"CES-D, RRS\", '%s'%(pre_)])\n",
    "\n",
    "##----task\n",
    "task_ = '%s (%.1f)'%(subjects_task, (round(subjects_task/subjects_demographics, 4)*100))\n",
    "rows.append([\"Task\", \"Task\", '%s'%(task_)])\n",
    "###eyetracking\n",
    "eye_ = '%s (%.1f)'%(subjects_eyetracking, (round(subjects_eyetracking/subjects_task, 4)*100))\n",
    "rows.append([\"Task\", \"Eyetracking\", '%s'%(eye_)])\n",
    "###eyetracking-used\n",
    "eyeused_ = '%s (%.1f)'%(subjects_eyetracking_used, (round(subjects_eyetracking_used/subjects_eyetracking, 4)*100))\n",
    "rows.append([\"Task\", \"Used\", '%s'%(eyeused_)])\n",
    "###calibrated\n",
    "calibrated_ = '%s (%.1f)'%(subjects_calibrated, (round(subjects_calibrated/subjects_eyetracking, 4)*100))\n",
    "rows.append([\"Task\", \"Calibrated\", '%s'%(calibrated_)])\n",
    "###behavioral\n",
    "behav_ = '%s (%.1f)'%(subjects_behavioral, (round(subjects_behavioral/subjects_task, 4)*100))\n",
    "rows.append([\"Task\", \"Behavioral\", '%s'%(behav_)])\n",
    "###behavioral-used\n",
    "behavused_ = '%s (%.1f)'%(subjects_behavioral_used, (round(subjects_behavioral_used/subjects_behavioral, 4)*100))\n",
    "rows.append([\"Task\", \"Used\", '%s'%(behavused_)])\n",
    "\n",
    "##----post assessment\n",
    "post_ = '%s (%.1f)'%(subjects_mmpi,(round(subjects_mmpi/subjects_demographics, 4)*100))\n",
    "rows.append([\"Post-Questionnaire\", \"MMPI\", '%s'%(post_)])\n",
    "\n",
    "#----to df\n",
    "descriptive = pd.DataFrame(rows)\n",
    "descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})\n",
    "del descriptive.index.name\n",
    "\n",
    "#----create html\n",
    "title = '<b>Table 1.</b> Schedule of Assessments.'\n",
    "##footnote\n",
    "no_webcam = '%s, %s%%'%(webcam_m['NotFoundError'], '%1.f'%(round(webcam_m['NotFoundError']/subjects_task, 5)*100))\n",
    "blocked_webcam = '%s, %s%%'%(webcam_m['NotAllowedError'], '%1.f'%(round(webcam_m['NotAllowedError']/subjects_task, 5)*100))\n",
    "footnote = [\n",
    "    '<div class=\"description\">',\n",
    "    'Data were collected from %s to %s. '%(date_start['metadata'],date_end['metadata']),\n",
    "    'Participants unable to meet the eyetracking device requirements (e.g. Chrome and Firefox, webcam, laptop or desktop) ',\n",
    "    'were placed in the behavioral version of dotprobe. Reasons include: participant dropout, ',\n",
    "    'no webcam present on the device (n=%s), '%(no_webcam),\n",
    "    'and blocked access of the webcam by the participants browser (n=%s)'%(blocked_webcam),\n",
    "    '<a class=\"note\" name=\"1\"><sup>1</sup></a>.',\n",
    "    '<br><br>',\n",
    "    'Once completing the <i>Pre-Questionnaire</i> on REDCap, participants are redirected to the task. ',\n",
    "    'Possible reasons for the drop off between <i>Pre-Questionnaire</i> (n=%s) \\\n",
    "    and <i>Task</i> (n=%s) samples can be due to: '%(subjects_cesd, subjects_task),\n",
    "    'Technical error during redirect, and disinterest in continuing to participate in the experiment. ',\n",
    "    '<br><br>',\n",
    "    'Also of note is the amount of participants that were successfully calibrated (n=%s, %1.f%%).'%(subjects_calibrated,\\\n",
    "                    (round(subjects_calibrated/subjects_eyetracking, 4)*100)),\n",
    "    '</div>'\n",
    "]\n",
    "footnote = ''.join(footnote)\n",
    "\n",
    "#create html\n",
    "html_name = 'task'\n",
    "html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "html = plot.html(config=config, df=descriptive, path=html_path, source=\"task\", name=html_name, title=title, footnote=footnote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### summary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(console['red'] + 'Step: summary data' + console['ENDC'])\n",
    "rows = []\n",
    "#-----------------------------testing group by cesd group (high, low) and trial type mean\n",
    "df_mean_std = df[['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias','gaze_bias',\n",
    "               'init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center','mean_gaze_toward',\n",
    "               'mean_gaze_away','var_gaze_bias','dp_gaze_cor','trialType_',\n",
    "               'luminance','m_diff_stim','m_diff_dotloc']]\n",
    "\n",
    "#------------------------get list of columns\n",
    "l_var = list(df_mean_std)\n",
    "l_var_gaze = ['gaze_bias','init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center',\n",
    "              'mean_gaze_toward','mean_gaze_away','var_gaze_bias']\n",
    "l_var_dp = ['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias']\n",
    "\n",
    "##--------crate rows\n",
    "df_mean_std = df_mean_std.groupby(['trialType_']).agg(['mean','std']).T.unstack(level=1)\n",
    "#collapse headers\n",
    "df_mean_std.columns = [' '.join(col).strip() for col in df_mean_std.columns.values]\n",
    "#combine columns\n",
    "df_mean_std['iaps'] = df_mean_std['iaps mean'].round(4).astype(str) + \" (\" + df_mean_std['iaps std'].round(4).astype(str) + \")\"\n",
    "df_mean_std['pofa'] = df_mean_std['pofa mean'].round(4).astype(str) + \" (\" + df_mean_std['pofa std'].round(4).astype(str) + \")\"\n",
    "#reindex and make new column for factor\n",
    "df_mean_std['variable'] = df_mean_std.index\n",
    "df_mean_std = df_mean_std.rename({'index': 'variable'}).reset_index(level=0,  drop=True)\n",
    "#create group column\n",
    "df_mean_std = df_mean_std.rename({'dp_gaze_corr': 'dpg_core'})\n",
    "df_mean_std['group'] = pd.np.where(df_mean_std['variable'].str.contains(\"gaze_\"), \"gaze\",\n",
    "                       pd.np.where(df_mean_std['variable'].str.contains(\"dp_\"), \"dotprobe\", \"task\"))\n",
    "\n",
    "df_mean_std = df_mean_std[['group','variable','iaps','pofa']]\n",
    "del df_mean_std.index.name\n",
    "\n",
    "#footnote\n",
    "footnote = [\n",
    "'<div class=\"description\">',\n",
    "'</div>\\n'\n",
    "]\n",
    "footnote = ''.join(footnote)\n",
    "\n",
    "#create html\n",
    "html_name = 'summary' \n",
    "html_path = config['output'] + \"/analysis/html/%s.html\"%(html_name)\n",
    "title = '<b>Table 1.</b> Summary Statistics (N = %s).'%(subjects_used)\n",
    "html = plot.html(config=config, df=df_mean_std, path=html_path, name=html_name, source=\"summary\", title=title, footnote=footnote)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
