{"cells":[{"cell_type":"markdown","source":[" #### mdl-R33-analysis"],"metadata":{}},{"source":["# Created on Sat May 1 15:12:38 2019  \n","# @author: Semeon Risom  \n","# @email: semeon.risom@gmail.com  \n","# @url: https://semeon.io/d/R33-analysis  \n","# @purpose: Hub for running processing and analysis."],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-------------------------------------------------------------------------------------------------------------------resources\n","'''\n","Useful python references\n","    - https://stackoverflow.com/questions/136097/what-is-the-difference-between-staticmethod-and-classmethod\n","    - https://realpython.com/python-modules-packages/\n","'''"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#---------------------------------------------------------------------------------------------------------------------imports\n","#----local\n","from imhr import download, model, plot, processing, raw, redcap, settings\n","\n","#----config\n","settings = settings()\n","console = settings.console\n","config = settings.config\n","filters = config['filter']\n","is_ = config['metadata']['is']\n","path_ = config['path']\n","#set parameters\n","config['processing']['task'] = 'gRT'\n","config['processing']['type'] = 'eyetracking'\n","config['processing']['single_subject'] = False\n","config['processing']['single_trial'] = False\n","\n","#----check if required libraries are available\n","is_['library'] = False\n","if is_['library']:\n","    settings.library()\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-----------------------------------------------------------------------------------------------------------imports continued\n","#----core\n","from pdb import set_trace as breakpoint\n","import pandas as pd\n","import glob, string, pytz, json, codecs\n","from datetime import datetime\n","\n","# set current date\n","date_start = []; date_end = []\n","date_now  = datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#------------------------------------------------------------------------------------------------------------------------init\n","processing = processing(config)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------------create pydoc\n","is_['pydoc'] = False\n","if is_['pydoc']:\n","    build = '/Users/mdl-admin/Desktop/mdl-R33-analysis/output/analysis/html/docs'\n","    source = '/Users/mdl-admin/Desktop/mdl-R33-analysis/docs/source'\n","    path = '/Users/mdl-admin/Desktop/mdl-R33-analysis/docs'\n","    processing.pydoc(path=path, build=build, source=source, copy=True) if __name__ == '__main__' else None\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-------------------------------------------------------------------------------------------------import raw data from server\n","is_['rawdata'] = False\n","if is_['rawdata']:\n","    console('Step: importing raw data from server', 'red')\n"," \t#----login\n","    hostname = 'panel.utweb.utexas.edu'\n","    username = \"utw10623\"\n","    password = \"mdlcla\"\n","    #----path\n","    log_path = path_['output']\n","    save_path = path_['output'] + '/raw/'\n","    r33_path = '/home/utweb/utw10623/public_html/a/r33/src/csv/data/subject'\n","    gRT_path = '/home/utweb/utw10623/public_html/a/webgazer/1/src/csv/data/subject'\n","    l_exp = [{'path':r33_path,'task':'r33','save':'r33'}, {'path':gRT_path,'task':'gRT','save':'gRT'}]\n","    #----start\n","    raw = raw()\n","    date = raw.download(l_exp=l_exp, log_path=log_path, save_path=save_path, hostname=hostname, username=username, password=password)\n"," \t#----storing download date\n","    date = {k:v for x in date for k,v in x.items()}[config['task']][0]\n","    #convert unix to ISO\n","    tz = pytz.timezone('US/Central')\n","    date = datetime.fromtimestamp(date, tz).replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S')\n","    #append\n","    date_end.append({'rawdata': date})\n","    del raw, date, tz\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------import REDCap data\n","is_['redcap'] = False\n","if is_['redcap']:\n","    console('Step: importing redcap data', 'red')\n","    #----login, paths\n","    redcap_url = 'https://redcap.prc.utexas.edu/redcap/api/'\n","    redcap_token = 'D04484634409375EA8CC34F5B71BC14A'\n","    demop = path_['output'] + \"/analysis/demographics.csv\"\n","    cesdp = path_['output'] + \"/analysis/cesd_rrs.csv\"\n","    mmpip = path_['output'] + \"/analysis/mmpi.csv\"\n","    #----cesd data\n","    redcap.cesd(path=cesdp, token=redcap_token, url=redcap_url, report_id='5485')\n","    #----demographics data\n","    redcap.demographics(path=demop, token=redcap_token, url=redcap_url, report_id='5487')\n","    #----mmpi data\n","    redcap.mmpi(path=mmpip, token=redcap_token, url=redcap_url, report_id='5486')\n","    date_end.append({'redcap':'%s'%(datetime.now().replace(microsecond=0).strftime('%Y-%m-%d %H:%M:%S'))})\n","    del demop, cesdp, mmpip, redcap\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#--------------------------------------------------------------------------start preprocessing behavioral or eyetracking data\n","is_['preprocessing'] = False\n","if is_['preprocessing']:\n","    console('Step: preprocessing data', 'red')\n","    #----parameters\n","    path = path_['output'] + \"/raw/\"\n","    subject = 31\n","    trial = 35\n","    #----if single subject, single trial\n","    if (config['processing']['single_subject']) and (config['processing']['single_trial']):\n","        print('processing: single subject, single trial')\n","        task_type = config['processing']['type']\n","        processing.run(path=path, task_type=task_type, single_subject=True, single_trial=True, subject=subject, trial=trial)\n","    #----else if single subject, all trials\n","    elif (config['processing']['single_subject']) and (not config['processing']['single_trial']):\n","        print('processing: single subject, all trials')\n","        task_type = config['processing']['type']\n","        processing.run(path=path, task_type=task_type, single_subject=True, single_trial=False, subject=subject)\n","    #----if all subjects, all trials\n","    elif (not config['processing']['single_subject']) and (not config['processing']['single_trial']):\n","        print('processing: all subjects, all trials')\n","        task_type = config['processing']['type']\n","        processing.run(path=path, task_type=task_type, single_subject=False, single_trial=False, isMultiprocessing=True, cores=7)\n","    #----finished\t\n","    date_end.append({'preprocessing':'%s'%(datetime.now().replace(microsecond=0).isoformat())})\n","pass\n","#############################################################################################################################\n","#############################################################################################################################\n","#############################################################################################################################\n","#############################################################################################################################\n","#############################################################################################################################"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["console('Step: demographics, plots, analysis', 'red')"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------------get metadata\n","is_['metadata'] = False\n","if is_['metadata']:\n","    console('processing metadata', 'red')\n","    #file path\n","    fpath = path_['output'] + \"/raw/\" + config['task']\n","    #save path\n","    spath = path_['output'] + \"/analysis/subject_metadata.csv\"\n","    subject_metadata = processing.subject_metadata(fpath=fpath, spath=spath)\n","    del fpath, spath, subject_metadata\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------------prepare data\n","is_['prepare'] = True\n","if is_['prepare']:\n","    #exclude participants\n","    exclude = [999999, 111111, 156]\n","    console('preparing data: %s'%(exclude), 'red')\n","    \n","    #read demographics and rename id=\"participant\"\n","    p_demo = path_['output'] + \"/analysis/demographics.csv\"\n","    df_demographics = pd.read_csv(p_demo, float_precision='high')\n","    ##exclude participants\n","    df_demographics = df_demographics[~df_demographics['participant'].isin(exclude)]\n","    #create gender column\n","    df_demographics['gender'] = df_demographics.apply(lambda x: 'female' if (x['female'] == 1 and x['male'] == 0) else \n","                                                      ('male' if (x['male'] == 1 and x['female'] == 0) else 'other'), axis=1)\n","    #replace eye color\n","    color=['Light Gray','Gray','Light Blue','Blue','Violet','Blue-Green','Green','Amber','Hazel',\n","    'Light Brown','Dark Brown','Black', 'Other']\n","    df_demographics['eye_color'] = df_demographics['eye_color'].replace([1,2,3,4,5,6,7,8,9,10,11,12,13], color)\n","    \n","    ##-------read cesd and rename id=\"participant\"\n","    p_cesd = path_['output'] + \"/analysis/cesd_rrs.csv\"\n","    df_cesd = pd.read_csv(p_cesd, float_precision='high')\n","    df_cesd = df_cesd.rename(columns={'record_id':'participant'})\n","    ##group cesd scores #bionomial\n","    df_cesd['cesd_group_'] = df_cesd.apply(lambda x: 1 if (x['cesd_score'] > 15) else 0, axis=1)\n","    df_cesd['cesd_group'] = df_cesd.apply(lambda x: 'High' if (x['cesd_score'] > 15) else 'Low', axis=1)\n","    ##exclude participants\n","    df_cesd = df_cesd[~df_cesd['participant'].isin(exclude)]\n","\n","    ##-------read mmpi\n","    p_mmpi = path_['output'] + \"/analysis/mmpi.csv\"\n","    df_mmpi = pd.read_csv(p_mmpi, float_precision='high')\n","    df_mmpi = df_mmpi.rename(columns={'record_id':'participant'})\n","    ##exclude participants\n","    df_mmpi = df_mmpi[~df_mmpi['participant'].isin(exclude)]\n","    \n","    ##-------read subject metadata\n","    p_subject = path_['output'] + \"/analysis/subject_metadata.csv\"\n","    df_metadata = pd.read_csv(p_subject, float_precision='high')\n","    # drop duplicate participant listings\n","    df_metadata = df_metadata.drop_duplicates(subset=\"participant\", keep=\"first\").reset_index(drop=True)\n","    # start and end dates\n","    date_start.append({'metadata':'%s'%(df_metadata['date'].min())})\n","    date_end.append({'metadata':'%s'%(df_metadata['date'].max())})\n","    # exclude participants\n","    df_metadata = df_metadata[~df_metadata['participant'].isin(exclude)]\n","    # rename variables\n","    df_metadata = df_metadata.rename(columns={\"isWindowSuccess\": \"is_calibrated\"})\n","    # all rows repersent participants\n","    df_metadata['is_task'] = True\n","    \n","    ##-------read bias summary and rename id=\"participant\"\n","    #if eyetracking\n","    if config['processing']['type'] == 'eyetracking': p_bias = path_['output'] + \"/bias/eyetracking_bias.csv\"\n","    #if behavioral\n","    else: p_bias = path_['output'] + \"/bias/behavioral_bias.csv\"\n","    \n","    #load\n","    df_bias = pd.read_csv(p_bias, float_precision='high')\n","    df_bias = df_bias.rename(columns={'id':'participant'})\n","    ###drop unusual data\n","    df_bias = df_bias.drop(df_bias[(df_bias['trialType'].isnull())].index)\n","    ##set dp_bias and gaze_bias as float\n","    df_bias['dp_bias'] = df_bias['dp_bias'].astype(float)\n","    if config['processing']['type'] == 'eyetracking': df_bias['gaze_bias'] = df_bias['gaze_bias'].astype(float)\n","    \n","    #set trialtype as text\n","    df_bias['trialType_'] = df_bias['trialType']\n","    df_bias['trialType'] = df_bias.apply(lambda x: 1 if (x['trialType'] == 'pofa') else 0, axis=1)\n","    ##exclude participants\n","    df_bias = df_bias[~df_bias['participant'].isin(exclude)]\n","    \n","    ##-------getting demographic data\n","    df_s = df_metadata.merge(df_cesd,on='participant').merge(df_demographics,on='participant')\n","    \n","    ##-------merge\n","    df = df_bias.merge(df_cesd,on='participant').merge(df_metadata,on='participant').merge(df_demographics,on='participant')\n","    #exclude participants\n","    df = df[~df['participant'].isin(exclude)]\n","    #rename columns\n","    ##rename microsoft os to msos, mac os to macos\n","    df['os'].replace(['Microsoft Windows', 'macOS','Chrome OS'], ['msos', 'macos', 'cos'], inplace=True)\n","    \n","    ##-------calculate difference between real stimulus, dotloc onset and real value #then merge medians with df\n","    merge = ['race','gender','is_normalvision','os','participant']\n","    df_error, onset_error, drop = processing.onset_diff(df0=df, merge=merge, cores=7)\n","    # save data\n","    csv_path = path_['output'] + \"/analysis/error.csv\"\n","    df_error.to_csv(csv_path, index=None)\n","    \n","    # combine exclude lists\n","    exclude = drop + exclude\n","    #update config\n","    config['metadata']['subjects']['exclude'] = exclude\n","    \n","    ##-------final version of df\n","    #merge\n","    df = pd.merge(df, df_error[['TrialNum_','m_rt','accuracy','m_diff_dotloc','m_diff_stim','participant']]\\\n","                  .drop_duplicates(subset=\"participant\", keep=\"first\"), how='left', on='participant')\n","\n","    ##export for seperate analysis in r\n","    csv_path = path_['output'] + \"/analysis/final_data.csv\"\n","    console('Step: export for R analysis: %s'%(csv_path), 'red')\n","    df.to_csv(csv_path, index=None)        \n","\n","    ##--------number of subjects\n","    # demographics\n","    l_demographics = df_demographics['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['demographics'] = l_demographics\n","    # task\n","    l_task = df_metadata['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['task'] = l_task\n","    # eyetracking\n","    l_eyetracking = df_metadata.loc[df_metadata['is_eyetracking'] == True]['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['eyetracking'] = l_eyetracking\n","    ## calibratied \n","    l_calibrated = df_metadata.loc[df_metadata['is_calibrated'] == True]['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['calibrated'] =  l_calibrated\n","    # behavioral\n","    l_behavioral = df_metadata.loc[df_metadata['is_eyetracking'] == False]['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['behavioral'] = l_behavioral\n","    # cesd\n","    l_cesd = df_cesd['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['cesd'] = l_cesd\n","    # mmpi\n","    l_mmpi = df_mmpi['participant'].astype('int').to_list()\n","    config['metadata']['subjects']['mmpi'] = l_mmpi\n","    # webcam\n","    config['metadata']['subjects']['webcam'] = df_metadata.drop_duplicates(subset=\"participant\",\n","          keep=\"first\").loc[:,'WebcamMessage'].value_counts().to_dict()\n","\n","    # get actual participants used in analysis\n","    subjects_eyetracking_used = len(glob.glob(path_['output'] + \"/tlbs/eyetracking/*.csv\"))\n","    subjects_behavioral_used = len(glob.glob(path_['output'] + \"/tlbs/behavioral/*.csv\"))\n","                \n","    # get subjects used\n","    if config['processing']['type'] == 'eyetracking':\n","        subjects_used = config['metadata']['subjects']['eyetracking']\n","    else:\n","        subjects_used = config['metadata']['subjects']['behavioral']\n","        \n","    ##--------date\n","    date_start = dict((key,d[key]) for d in date_start for key in d)\n","    date_end = dict((key,d[key]) for d in date_end for key in d)\n","    \n","    del p_bias, p_cesd, p_demo, p_mmpi, p_subject, color, csv_path\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#------------------------------------------------------------------------------------------------------demographic statistics\n","is_['demographic'] = True\n","if is_['demographic']:\n","    #-----------------------------get max, min values\n","    total = {}\n","    #----drop non-eyetracking participants\n","    df_d = df_s[df_s['participant'].isin(l_eyetracking)]\n","    \n","    #----subset dataframe to cesd low and high\n","    #cesd high\n","    df_dh = df_d.loc[df_d['cesd_score'] > 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n","    #cesd low\n","    df_dl = df_d.loc[df_d['cesd_score'] <= 15].drop_duplicates(subset=\"participant\", keep=\"first\")\n","    \n","    #get total used\n","    total['High'] = len(df_dh['participant'].unique())\n","    total['Low'] = len(df_dl['participant'].unique())\n","    total['all'] = len(l_eyetracking)\n","    \n","    #-----------------------------descriptive demographic stats\n","    console('Step: descriptive demographic', 'red')\n","    rows = []\n","    #----age, cesd, rrs\n","    l_label = ['Age','Center for Epidemiologic Studies Depression Scale',\"Ruminative Response Scale\"]\n","    l_category = ['age','cesd_score','rrs_brooding']\n","    for label, category in zip(l_label, l_category):\n","        low = [str(round(df_dl[category].mean(),1)), '(%s)'%(str(round(df_dl[category].std(),1)))]\n","        high = [str(round(df_dh[category].mean(),1)), '(%s)'%(str(round(df_dh[category].std(),1)))]\n","        rows.append([label,\"(SD)\", low[0], low[1], high[0], high[1]])\n","     \n","    #----normal vision, corrective vision, handedness, hispanic\n","    l_label = ['Vision','Vision','Handedness (Right)','Hispanic or Latino']\n","    l_group = ['Normal','Corrective','Right','(%)']\n","    l_category = ['is_normalvision','is_corrective','handedness','hispanic']\n","    l_condition = [True,True,'Right',True]\n","    #Handedness (Right), Corrective, is_corrective, True\n","    for label, group, category, condition in zip(l_label, l_group, l_category, l_condition):\n","        #cesd low\n","        df_sum = df_d.loc[(df_d[category] == condition) & (df_d['cesd_group'] == 'Low')]\n","        count = int(len(df_sum.index))\n","        pct = '%.1f'%(round(count/total['Low'], 4)*100)\n","        low = [count,'(%s)'%(pct)]\n","        #cesd high\n","        df_sum = df_d.loc[(df_d[category] == condition) & (df_d['cesd_group'] == 'High')]\n","        count = len(df_sum.index)\n","        pct = '%.1f'%(round(count/total['High'], 4)*100)\n","        high = [count,'(%s)'%(pct)]\n","        #append\n","        rows.append(['%s'%(label), group, low[0], low[1], high[0], high[1]])\n","            \n","    #----eye color, gender, race\n","    l_label = ['Race','Gender','Eye Color']\n","    l_category = ['race','gender','eye_color']\n","    for label, category in zip(l_label, l_category):\n","        l_group = df_d[category].unique().tolist()\n","        for group in l_group:\n","            #cesd low\n","            df_sum = df_d.loc[(df_d[category] == group) & (df_d['cesd_group'] == 'Low')]\n","            count = int(len(df_sum.index))\n","            pct = '%.1f'%(round(count/total['Low'], 4)*100)\n","            low = [count,'(%s)'%(pct)]\n","            #cesd high\n","            df_sum = df_d.loc[(df_d[category] == group) & (df_d['cesd_group'] == 'High')]\n","            count = len(df_sum.index)\n","            pct = '%.1f'%(round(count/total['High'], 4)*100)\n","            high = [count,'(%s)'%(pct)]\n","            #append\n","            group = group.title().replace('Or','or').replace('And','and').replace('Of','of').replace('The','the')\n","            rows.append(['%s'%(label), group, low[0], low[1], high[0], high[1]])\n","\n","    #-----to df\n","    # create new columns\n","    cesd_col = ['CESD < 16<span class=\"nval\">(n=%s)</span>'%(total['Low']), 'CESD ≥ 16<span class=\"nval\">(n=%s)</span>'%(total['High'])]\n","    descriptive = pd.DataFrame(rows)\n","    descriptive = descriptive.rename(columns={0:'ID',1:'Group', 2:cesd_col[0], 3:'a', 4:cesd_col[1], 5:'b'})\n","    # sort order\n","    l_sort = ['Age','Vision','Eye Color','Handedness (Right)','Gender','Hispanic or Latino','Race', \n","              'Center for Epidemiologic Studies Depression Scale','Ruminative Response Scale']\n","    descriptive['ID'] = pd.Categorical(descriptive['ID'], l_sort)\n","    # sort\n","    descriptive = descriptive.sort_values(['ID',cesd_col[0]], ascending=[True, False])\n","    # merge columns\n","    descriptive[cesd_col[0]] = descriptive[[cesd_col[0], 'a']].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n","    descriptive[cesd_col[1]] = descriptive[[cesd_col[1], 'b']].apply(lambda x: ' '.join(x.astype(str)), axis=1)\n","    # delete\n","    descriptive.drop(descriptive.columns[[3,5]], axis=1, inplace=True)\n","    del descriptive.index.name\n","    \n","    #-----create html\n","    html_name = 'demographic'\n","    html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_name)\n","    title = '<b>Table 1.</b> Participant characteristics (N = %s).'%(total['all'])\n","    footnote = \"<div id='note'>N = Sample size of eyetracking participants. Total participants = %s.\"%(config['metadata']['subjects']['task'])\n","    html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, \n","                      source=\"demographic\", title=title, footnote=footnote)\n","    \n","    #breakpoint()\n","    #del df_sum, index, value, above_pct, rows, html_path, title, html, html_name\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-----------------------------------------------------------------------------------------------------------list of variables\n","is_['variables'] = True\n","if is_['variables']:\n","    console('Step: list of variables', 'red')\n","    df_variables = processing.variables(df=df)\n","    \n","    ##create html\n","    html_name = 'definitions'\n","    html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_name)\n","    title = '<b>Table 1.</b> Task Variables and Definitions.'\n","    html = plot.html(config=config, df=df_variables, path=html_path, name=html_name, source=\"definitions\", title=title)\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------descriptive device\n","is_['descriptive'] = True\n","if is_['descriptive']:\n","    console('Step: descriptive device', 'red')\n","    rows = []\n","    ##--------os browser gpu type Webcam resolution Webcam message\n","    os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os'].value_counts()\n","    for index, value in os_.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Operating System\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del os_\n","    \n","    # ##--------os_version\n","    os_ = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'os_version'].value_counts()\n","    for index, value in os_.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Operating System version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del os_\n","        \n","    ##--------browser\n","    browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser'].value_counts()\n","    for index, value in browser.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Browser\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del browser\n","    \n","    ##--------browser_version\n","    browser = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'browser_version'].value_counts()\n","    for index, value in browser.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Browser version\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del browser\n","    \n","    ##--------gpu type \n","    gpu_type = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu_type'].value_counts()\n","    for index, value in gpu_type.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"GPU type\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del gpu_type\n","    \n","    ##--------webcam brand\n","    gpu = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'gpu'].value_counts()\n","    for index, value in gpu.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"GPU model\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del gpu\n","    \n","    ##--------devicepixelratio\n","    display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'devicePixelRatio'].value_counts().sort_index(axis=0)\n","    for index, value in display.items():\n","        index = '%.2f'%(round(index, 2))\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"devicePixelRatio\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del display\n","        \n","    ##--------display resolution\n","    display = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'monitorSize'].value_counts()\n","    for index, value in display.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Display resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del display\n","    \n","    ##--------webcam message\n","    webcam_m = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'WebcamMessage'].value_counts()\n","    for index, value in webcam_m.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Webcam message\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    \n","    ##--------webcam brand\n","    webcamb = df_s.drop_duplicates(subset=\"participant\", keep=\"first\").loc[:,'webcam_brand'].value_counts()\n","    for index, value in webcamb.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Webcam brand\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del webcamb   \n","    \n","    ##--------Webcam resolution\n","    webcamr = df_s[~df_s['webcamSize'].isin(['.x.'])].drop_duplicates(subset=\"participant\",\n","                    keep=\"first\").loc[:,'webcamSize'].value_counts()\n","    for index, value in webcamr.items():\n","        above_pct = '%.1f'%(round(value/len(config['metadata']['subjects']['task']), 4)*100)\n","        rows.append([\"Webcam resolution\",\"%s\"%(index), '%s (%s)'%(value,above_pct)])\n","    del webcamr\n","    \n","    #-------to df\n","    descriptive = pd.DataFrame(rows)\n","    descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:'Statistic'})\n","    del descriptive.index.name\n","    \n","    #footnote\n","    footnote = [\n","    '<div class=\"description\">\\n',\n","        'During data collection, participants screen resolution were multiplied by the pixel density ratio, or\\\n","        <a class=\"ref\" href=\"https://developer.mozilla.org/en-US/docs/Web/API/Window/devicePixelRatio\"><i>devicePixelRatio</i></a>\\\n","        (i.e. width = screen.width / devicePixelRatio = 1920 * 1.5). This was done with the intent of storing true device \\\n","        physical resolution. However to simplify analysis using webgazer, which uses the same initial value \\\n","        to calculate gaze location, participants screen resolution is reverted back to its original value.\\n',\n","    '</div>\\n']\n","    footnote = ''.join(footnote)\n","    \n","    #create html\n","    html_name = 'device'\n","    html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_name)\n","    title = '<b>Table 1.</b> Device characteristics (N = %s).'%(config['metadata']['subjects']['task'])\n","    html = plot.html(config=config, df=descriptive, path=html_path, name=html_name, source=\"device\", title=title, footnote=footnote)\n","    del index, value, above_pct, rows, html_path, title, footnote, html, html_name\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#------------------------------------------------------------------------------------------------------------descriptive task\n","is_['task'] = True\n","if is_['task']:\n","    console('Step: descriptive task', 'red')\n","    rows = []\n","    total = {}\n","    \n","    #----totals\n","    total['Low'] = len(df_s['participant'].loc[(df_s['cesd_group'] == 'Low')].unique())\n","    total['High'] = len(df_s['participant'].loc[(df_s['cesd_group'] == 'High')].unique())\n","    \n","    #----pre-task: demographics\n","    score = []\n","    for cesd in ['Low','High']:\n","        df_sum = df_s.loc[(df_s['cesd_group'] == cesd)]\n","        count = len(df_sum.index)\n","        pct = '%.1f'%(round(count/total[cesd], 4)*100)\n","        score.append('%s (%s)'%(count, pct))\n","    #add\n","    rows.append([\"Pre-Questionnaire\", \"Demographics\", score[0], score[1]])\n","    \n","    #----pre-task: cesd, rss\n","    score = []\n","    for cesd in ['Low','High']:\n","        df_sum = df_s.loc[(df_s['cesd_group'] == cesd)]\n","        count = len(df_sum.index)\n","        pct = '%.1f'%(round(count/total[cesd], 4)*100)\n","        score.append('%s (%s)'%(count, pct))\n","    #add\n","    rows.append([\"Pre-Questionnaire\", \"CES-D, RRS\", score[0], score[1]])\n","    \n","    #----task\n","    l_label = ['Task','Task','Task','Task']\n","    l_group = ['Task','Eyetracking','Calibrated','Behavioral']\n","    l_category = ['is_task','is_eyetracking','is_calibrated','is_eyetracking']\n","    l_bool = [True,True,True,False]\n","    #convert to bool\n","    df_s[l_category] = df_s[l_category].astype('bool')\n","    #for each\n","    for label, group, category, bool_ in zip(l_label, l_group, l_category, l_bool):\n","        # for each cesd score\n","        score = []\n","        for cesd in ['Low','High']:\n","            df_sum = df_s.loc[(df_s[category] == bool_) & (df_s['cesd_group'] == cesd)]\n","            count = int(len(df_sum.index))\n","            pct = '%.1f'%(round(count/total[cesd], 4)*100)\n","            score.append('%s (%s)'%(count, pct))\n","        # add\n","        rows.append([label, group, score[0], score[1]])\n","    \n","    #----post-task: mmpi\n","    df_mmpi2 = df_mmpi.merge(df_s,on='participant')\n","    score = []\n","    for cesd in ['Low','High']:\n","        df_sum = df_mmpi2.loc[(df_mmpi2['cesd_group'] == cesd)]\n","        count = len(df_sum.index)\n","        pct = '%.1f'%(round(count/total[cesd], 4)*100)\n","        score.append('%s (%s)'%(count, pct))\n","    #add\n","    rows.append([\"Post-Questionnaire\", \"MMPI\", score[0], score[1]])       \n","\n","    #----to df\n","    descriptive = pd.DataFrame(rows)\n","    low='CESD < 16 <span class=\"nval\">(n=%s)</span>'%(total['Low'])\n","    high='CESD ≥ 16 <span class=\"nval\">(n=%s)</span>'%(total['High'])\n","    descriptive = descriptive.rename(columns={0:'ID',1:'Group',2:low,3:high})\n","    del descriptive.index.name\n","    \n","    #----create html\n","    title = '<b>Table 1.</b> Schedule of Assessments.'\n","    # no_webcam\n","    total = config['metadata']['subjects']['webcam']['NotFoundError']/len(config['metadata']['subjects']['task'])\n","    no_webcam = '%s, %s%%'%(config['metadata']['subjects']['webcam']['NotFoundError'], '%1.f'%(round(total, 5)*100))\n","    # blocked_webcam\n","    total = config['metadata']['subjects']['webcam']['NotAllowedError']/len(config['metadata']['subjects']['task'])\n","    blocked_webcam = '%s, %s%%'%(config['metadata']['subjects']['webcam']['NotAllowedError'], '%1.f'%(round(total, 5)*100))\n","    #calibrated\n","    total = len(config['metadata']['subjects']['calibrated'])/len(config['metadata']['subjects']['eyetracking'])\n","    footnote = [\n","        '<div class=\"paragraph\">',\n","            '<a class=\"note\" name=\"1\"><sup>1</sup></a>',\n","            'Data were collected from %s to %s. '%(date_start['metadata'],date_end['metadata']),\n","            'Participants unable to meet the eyetracking device requirements (e.g. Chrome and Firefox, webcam, laptop or desktop) ',\n","            'were placed in the behavioral version of dotprobe. Reasons include: participant dropout, ',\n","            '<a tabindex=\"0\" class=\"popover-anchor\" link-id=\"iaps\" data-toggle=\"popover\" data-content=\"NotFoundError\" \\\n","            title=\"WebcamMessage\">no webcam present on the device</a> (n=%s) and '%(no_webcam),\n","            '<a tabindex=\"0\" class=\"popover-anchor\" link-id=\"iaps\" data-toggle=\"popover\" data-content=\"NotAllowedError\" \\\n","            title=\"WebcamMessage\">blocked access of the webcam</a> by the participants browser (n=%s).</div>'%(blocked_webcam),\n","        '<div class=\"paragraph\">',\n","            'Once completing the <i>Pre-Questionnaire</i> on REDCap, participants are redirected to the task. ',\n","            'Possible reasons for the drop off between <i>Pre-Questionnaire</i> (n=%s) \\\n","            and <i>Task</i> (n=%s) samples can be due to: '\\\n","            %(len(config['metadata']['subjects']['cesd']), len(config['metadata']['subjects']['task'])),\n","            'Technical error during redirect, and disinterest in continuing to participate in the experiment. ',\n","        '</div>'\n","    ]\n","    footnote = ''.join(footnote)\n","    \n","    #create html\n","    html_name = 'task'\n","    html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_name)\n","    html = plot.html(config=config, df=descriptive, path=html_path, source=\"task\", name=html_name, title=title, footnote=footnote)\n","    \n","    del html_name, html_path, no_webcam, blocked_webcam, descriptive, total, df_mmpi2, score, cesd, count, pct, rows\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#----------------------------------------------------------------------------------------------------------------summary data\n","is_['summary'] = True\n","if is_['summary']:\n","    console('Step: summary data', 'red')\n","    rows = []\n","    #-----------------------------testing group by cesd group (high, low) and trial type mean\n","    df_mean_std = df[['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias','gaze_bias',\n","                    'init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center','mean_gaze_toward',\n","                    'mean_gaze_away','var_gaze_bias','dp_gaze_cor','trialType_',\n","                    'luminance','m_diff_stim','m_diff_dotloc']]\n","    \n","    #------------------------get list of columns\n","    l_var = list(df_mean_std)\n","    l_var_gaze = ['gaze_bias','init_gaze_bias','final_gaze_bias','n_gaze_valid','n_gaze_toward','pct_gaze_center',\n","                  'mean_gaze_toward','mean_gaze_away','var_gaze_bias']\n","    l_var_dp = ['dp_bias','n_dp_valid','pct_dp_toward','mean_dp_toward','mean_dp_away','var_dp_bias']\n","    \n","    ##--------crate rows\n","    df_mean_std = df_mean_std.groupby(['trialType_']).agg(['mean','std']).T.unstack(level=1)\n","    #collapse headers\n","    df_mean_std.columns = [' '.join(col).strip() for col in df_mean_std.columns.values]\n","    #combine columns\n","    df_mean_std['iaps'] = df_mean_std['iaps mean'].round(4).astype(str) + \" (\" + df_mean_std['iaps std'].round(4).astype(str) + \")\"\n","    df_mean_std['pofa'] = df_mean_std['pofa mean'].round(4).astype(str) + \" (\" + df_mean_std['pofa std'].round(4).astype(str) + \")\"\n","    #reindex and make new column for factor\n","    df_mean_std['variable'] = df_mean_std.index\n","    df_mean_std = df_mean_std.rename({'index': 'variable'}).reset_index(level=0,  drop=True)\n","    #create group column\n","    df_mean_std = df_mean_std.rename({'dp_gaze_corr': 'dpg_core'})\n","    df_mean_std['group'] = pd.np.where(df_mean_std['variable'].str.contains(\"gaze_\"), \"gaze\",\n","                            pd.np.where(df_mean_std['variable'].str.contains(\"dp_\"), \"dotprobe\", \"task\"))\n","    \n","    df_mean_std = df_mean_std[['group','variable','iaps','pofa']]\n","    del df_mean_std.index.name\n","    \n","    #footnote\n","    footnote = [\n","    '<div class=\"description\">',\n","    '</div>\\n'\n","    ]\n","    footnote = ''.join(footnote)\n","    \n","    #create html\n","    html_name = 'summary' \n","    html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_name)\n","    title = '<b>Table 1.</b> Summary Statistics (N = %s).'%(subjects_used)\n","    html = plot.html(config=config, df=df_mean_std, path=html_path, name=html_name, source=\"summary\", title=title, footnote=footnote)\n","    \n","    del l_var, l_var_gaze, l_var_dp, rows, html_name, html_path, title, footnote, html\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-----------------------------------------------------------------------------------------------------------------save config\n","is_['config'] = True\n","if is_['config']:\n","    # add definitions to config\n","    config = settings.definitions(config)\n","    # save\n","    p_json = path_['output'] + \"/analysis/config.json\"\n","    with open(p_json, 'w') as f:\n","        json.dump(config, codecs.open(p_json, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n","        \n","        \n","    \n","        \n","        \n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-----------------------------------------------------------------------------------------------------------------------plots\n","is_['plots'] = True\n","if is_['plots']:\n","    console('Step: plots', 'red')\n","    is_['single'] = True\n","    #%%------------------------------------------------------------------------------------------------------------------\n","    #-----------------------------------------------------------------------------------------------single subject: trial\n","    if is_['single']:\n","        \"\"\"\n","        Resources:\n","        - https://media.springernature.com/original/springer-static/image/\n","            art%3A10.3758%2Fs13428-017-0913-7/MediaObjects/13428_2017_913_Figa_HTML.gif\n","        \"\"\"\n","        #-------------------------------------------------single subject bokeh coordinates (all trials)\n","        console('Step: bokeh_trial()', 'red')\n","        subject = 31\n","        session = 0\n","        #data\n","        path_sns = path_['output'] + \"/process/data/eyetracking/%s_%s.csv\"%(subject,session)\n","        df_single = pd.read_csv(path_sns, float_precision='high')\n","        #rename\n","        df_single = df_single.rename(columns={\"LEmotion\":\"left_mood\",\"REmotion\":\"right_mood\"})\n","        #exclude columns\n","        df_single = df_single[['participant','session','subsession','TrialNum','timestamp','trialType','isCongruent',\n","                                'left_mood','right_mood','monitorSize.px',\n","                                'x','y','marker','sg_x','sg_y','sg_class',\n","                                'sg_fix_all','sg_fix_index',\n","                                'sg_all_bounds','sg_fix_bounds','fix_num',\n","                                'left_bound','right_bound','dwell']]\n","        \n","        #get rois\n","        stim_bounds, roi_bounds = processing.roi(filters=filters, flt=filters[0][1], df=df_single, manual=True)\n","        #for each subject\n","        flt = 'sg'\n","        for idx in range(198):\n","            #subset data\n","            df_single_ = df_single[df_single['TrialNum'].isin([idx])].reset_index(drop=True)\n","            #draw plot\n","            bokeh_plot = plot.bokeh_trial(config=config, df=df_single_, stim_bounds=stim_bounds, roi_bounds=roi_bounds, flt='sg')\n","            ##get is_congruent\n","            isCongruent = \"congruent\" if df_single_['isCongruent'][0] == True else \"incongruent\"\n","            #html\n","            title = \"(%s) Participant %s, session %s\"%(isCongruent, subject, session)\n","            html_path = path_['output'] + \"/analysis/html/trial/%s_%s_%s.html\"%(subject,session,idx)\n","            html = plot.html(config=config, path=html_path, plots=bokeh_plot, source=\"bokeh\", \n","                              display=\"trial\", trial=idx, title=title)\n","                                 \n","        del idx, title, path_sns, bokeh_plot, df_single_, html_path, html, subject, session\n","    #%%------------------------------------------------------------------------------------------------------------------\n","    #-----------------------------------------------------------------------------single subject: calibration, validation\n","        print(console['green'] + 'bokeh_calibration()', 'red')\n","        subject = 'shellie'\n","        session = 1\n","        #monitorSize = [1920,1080] #session 0\n","        monitorSize = [1280,800] #session 1\n","        \n","        #for calibration/validation event 0,1,2\n","        for block in range(1,4):\n","            #---import data\n","            path_sns = path_['output'] + \"/calibration/%s_%s_%s_calibration.csv\"%(subject, session, block)\n","            df_cv = pd.read_csv(path_sns, float_precision='high')\n","            #----get calibration points\n","            cxy = df_cv.groupby(['cx','cy']).size().reset_index().rename(columns={0:'count'})\n","            #calibration and validation\n","            for event, full in zip(['isCalibrating','isValidating'],['calibration','validation']):\n","                #subset data\n","                df_cv_ = df_cv.loc[df_cv['event'] == event].reset_index(drop=True)\n","                #draw plot\n","                bokeh_plot = plot.bokeh_calibration(config=config, df=df_cv_, cxy=cxy, event=full, monitorSize=monitorSize)\n","                #html\n","                title = \"Participant %s\"%(subject)\n","                html_path = path_['output'] + \"/analysis/html/cv/%s_%s_%s_%s.html\"%(subject, session, block, full)\n","                html = plot.html(config=config, path=html_path, plots=bokeh_plot, source=\"bokeh\", title=title, \n","                                  footnote=config['def'][full], display=full, trial=full, block=full, session=session)\n","                             \n","        #del title, event, full, path_sns, bokeh_plot, html_path, html\n","\n","    is_['density'] = True\n","    #%%------------------------------------------------------------------------------------------------------------------\n","    #--------------------------------------------------------------------------------------------------------density plot\n","    if is_['density']:\n","        console('Step: density_plot()', 'red')\n","        #Computes and draws density plot (kernel density estimate), which is a smoothed version of the histogram. \n","        #This is used as a gage for normality\n","        df_density = df[['participant','trialType_','m_rt',\n","                          'm_diff_dotloc','m_diff_stim','luminance',\n","                          'rrs_brooding','cesd_score','cesd_group',\n","                          'dp_bias','n_dp_valid','gaze_bias','n_gaze_valid',\n","                          'var_gaze_bias','final_gaze_bias']].loc[df['nested'] == 'subject']   \n","        \n","        #----exclude\n","        df_density = df_density[~df_density['participant'].isin(exclude)]   \n","        \n","        #file\n","        title = string.capwords('kernel density estimate')\n","        \n","        #create images\n","        density, html_plots = plot.density_plot(config=config, df=df_density, title=title)\n","        #description of plots\n","        intro = \"The kernel density estimate (kde) is used here as a quick check of normality for each of the variables of \\\n","        interest in the model. All data here has been nested by subject. %s\"%(config['def']['exclude'])\n","        #create html\n","        html_path = path_['output'] + \"/analysis/html/density.html\"\n","        html = plot.html(config=config, path=html_path, plots=html_plots, source=\"plots\", intro=intro)\n","        del density, intro, html_plots, html_path, html, title\n","        \n","    is_['corr'] = True \n","    #%%------------------------------------------------------------------------------------------------------------------\n","    #--------------------------------------------------------------------------------------------------correlation matrix\n","    if is_['corr']:\n","        console('Step: corr_matrix()', 'red')\n","        #run correlation matrix\n","        df_corr = df[['dp_bias','n_dp_valid','var_dp_bias',\n","                      'gaze_bias','n_gaze_valid','var_gaze_bias','final_gaze_bias',\n","                      'rrs_brooding','cesd_score',\n","                      'm_rt','m_diff_dotloc','m_diff_stim',\n","                      'luminance']].loc[df['nested'] == 'subject']\n","        \n","        #file\n","        file = 'corr_matrix'\n","        method = 'spearman'\n","        title = string.capwords('%s correlation coefficient matrix (p-value).'%(method))\n","        \n","        path = path_['output'] + \"/analysis/html/%s.html\"%(file)\n","        corr_matrix = plot.corr_matrix(config=config, df=df_corr, path=path, title=title, method=method)\n","        del path, corr_matrix, file, title, method\n","    \n","    is_['boxplot'] = True\n","    #%%------------------------------------------------------------------------------------------------------------------\n","    #-------------------------------------------------------------------------------------------------------------boxplot\n","    if is_['boxplot']:\n","        console('Step: boxplot()', 'red')\n","        #----create temp df\n","        html_plots = []\n","        html_file = 'rt_boxplot'\n","        x = ['race','gender','is_normalvision','os']\n","        cat = 'demographics'\n","\n","        #----exclude\n","        df_ = df_error[~df_error['participant'].isin(exclude)]\n","        \n","        ##-------response time\n","        y = 'Key_Resp_rt'\n","        intro = 'This was done to compare differences in response time between os, webcamsize, gender, race and other factors.'\n","        footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n","        races', 'Black or African American', 'None of the above' were excluded here for displaying purposes.\\\n","        %s\"%(config['def']['exclude'])\n","        #create plot\n","        file = 'rt_boxplot'\n","        title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n","        sns_path = path_['output'] + \"/analysis/html/img/%s.png\"%(file)\n","        plot.boxplot(config=config, df=df_, path=sns_path, x=x, y=y, cat=cat)\n","        html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n","        \n","        ##-------diff_dotloc\n","        y = 'diff_dotloc'\n","        intro = 'This was done to compare differences between expected and true dotloc onset between os, webcamsize, \\\n","        gender, race and other factors.'\n","        footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n","        races', 'Black or African American', 'None of the above' were excluded here for displaying purposes.\\\n","        %s\"%(config['def']['exclude'])\n","        #create plot\n","        file = 'dotloc_boxplot'\n","        title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n","        sns_path = path_['output'] + \"/analysis/html/img/%s.png\"%(file)\n","        plot.boxplot(config=config, df=df_, path=sns_path, x=x,y=y, cat=cat)\n","        html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n","        \n","        ##-------diff_stim\n","        y = 'diff_stim'\n","        intro = 'This was done to compare differences between expected and true stim onset between os, webcamsize, \\\n","        gender, race and other factors.'\n","        footnote = \"Data collapsed by subject. Participants identified 'race' as 'American Indian or Alaska Native','Two or more \\\n","        races', 'Black or African American', 'None of the above' were excluded here for displaying purposes.\\\n","        %s\"%(config['def']['exclude'])\n","        #create plot\n","        file = 'stim_boxplot'\n","        title = 'Boxplots, %s (N = %s)'%(y, subjects_used)\n","        sns_path = path_['output'] + \"/analysis/html/img/%s.png\"%(file)\n","        plot.boxplot(config=config, df=df_, path=sns_path, x=x,y=y, cat=cat)\n","        html_plots.append({\"title\":title,\"file\":\"%s.png\"%(file),\"footnote\":footnote})\n","        \n","        #-------save folders\n","        html_path = path_['output'] + \"/analysis/html/%s.html\"%(html_file)\n","        html = plot.html(config=config, path=html_path, plots=html_plots, source=\"plots\", display=\"boxplot\", intro=intro)\n","        del intro, html_file, file, title, html_path, html, cat, x, y, footnote\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#---------------------------------------------------------------------------------------------------------------------methods\n","is_['methods'] = True\n","if is_['methods']:\n","    '''\n","    Resources\n","    ---------\n","    Example articles for reporting methods/results:\n","        - lmer: https://www.sciencedirect.com/science/article/pii/S0028393217301197#bib19\n","        - classify: https://www.sciencedirect.com/science/article/pii/S0028393217301197#bib19\n","        - roi: https://www.sciencedirect.com/science/article/pii/S0028393217301197#bib19\n","        - luminance: https://ars.els-cdn.com/content/image/1-s2.0-S0022096516301023-mmc1.pdf\n","    '''\n","    # #----load config\n","    # p = path_['output'] + \"/analysis/config.json\"\n","    # with open(p) as f:\n","    #     config_ = json.loads(f.read())\n","    config_ = config\n","    console('fix config', 'red')\n","        \n","    #----start\n","    def_ = config_['metadata']['def']\n","    cite_ = config_['metadata']['cite']\n","    source = 'methods'\n","    title = 'Methods'\n","    path = path_['output'] + \"/analysis/html/%s.html\"%(source)\n","    methods = [\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\" id=\"webgazer\">Webgazer.js</div>',\n","            '<span>' + def_['filter'] + '</span>',\n","        '</div>',\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\" id=\"task_design\">Task Design </div>',\n","            '<span>' + def_['task_design'] + '</span>',\n","        '</div>',\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\">Calibration/Validation</div>',\n","            '<div class=\"subtitle2\" id=\"calibration\">Calibration</div>',\n","            '<span>' + def_['calibration'] + '</span>',\n","            '<div class=\"subtitle2\" id=\"validation\">Calibration</div>',\n","            '<span>' + def_['validation'] + '</span>',\n","        '</div>',\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\">Preprocessing</div>',\n","            '<span>' + cite_['preprocessing'] + '</span>',\n","            '<div class=\"subtitle2\" id=\"filter\">Filtering</div>',\n","            '<span>' + '' + '</span>',\n","            '<div class=\"subtitle2\" id=\"classify\">Classifying Events</div>',\n","            '<span>' + cite_['hmm'] + '</span>',\n","            '<div class=\"subtitle2\" id=\"classify\">semeon: use this as example for writing (filtering)</div>',\n","            '<span>' + def_['filter'] + '</span>',\n","        '</div>',\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\" id=\"model\">Modelling</div>',\n","            '<span>' + ''+ '</span>',\n","        '</div>',\n","        '<div class=\"paragraph\">',\n","            '<div class=\"subtitle\">Outliers</div>',\n","            '<div class=\"subtitle2\" id=\"device\">Device</div>',\n","            '<span>' + ''+ '</span>',\n","            '<div class=\"subtitle2\" id=\"onset_error\">Onset Error</div>',\n","            '<span>' + '' + '</span>',\n","        '</div>'\n","    ]\n","    methods = ('\\n\\t'.join(map(str, methods)))\n","    html = plot.html(plots=methods, config=config, path=path, source=source, title=title, name='methods')\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#--------------------------------------------------------------------------------------------------------------------analysis\n","is_['analysis'] = True\n","if is_['analysis']:\n","        '''\n","        Resources\n","        ---------\n","        Choosing the best model:\n","            - https://rpsychologist.com/r-guide-longitudinal-lme-lmer\n","            - https://stats.idre.ucla.edu/other/mult-pkg/whatstat/\n","            - https://stats.stackexchange.com/a/303592\n","            - https://tsmatz.wordpress.com/2017/08/30/glm-regression-logistic-poisson-gaussian-gamma-tutorial-with-r/\n","        Example articles for reporting methods/results:\n","            - lmer: https://www.sciencedirect.com/science/article/pii/S0028393217301197#bib19\n","            - \n","        '''\n","        #----start\n","        is_['dwell'] = True"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#-----------------------------------------------------------------------------------------------------------anova: dwell time\n","        if is_['dwell']:\n","            console('Step: ANOVA (dwell time)', 'red')\n","            effects = {}\n","            \n","            #----load config\n","            # p = path_['output'] + \"/analysis/config.json\"\n","            # with open(p) as f:\n","            #     config_ = json.loads(f.read())\n","            config_ = config\n","            console('fix config', 'red')   \n","                \n","            #----exclude\n","            exclude = config_['metadata']['subjects']['exclude']\n","            \n","            #----load data\n","            p = path_['output'] + \"/analysis/final_data.csv\"\n","            df_ = pd.read_csv(p, float_precision='high')\n","            \n","            #-----parameters\n","            # dependent variable\n","            y = 'dwell_time'\n","            # main effects\n","            effects['main'] = {\n","                'cesd_group': 'categorical',\n","                'aoi': 'categorical',\n","                'trialType': 'categorical'\n","            }\n","            # random effects\n","            effects['random'] = {\n","                'participant': 'categorical'\n","            }\n","            # formula\n","            f = \"%s ~ cesd_group + aoi + trialType + (1|participant)\"%(y)\n","            \n","            #----save data for access by R and for calculating dwell time\n","            csv = \"dwell_data.csv\"\n","            p = path_['output'] + \"/analysis/html/model/anova/\"\n","        \n"," \t\t\t#-----calculate dwell time using multiprocessing\n"," \t\t\t# use __name__ to protect main module\n","            df_dwell, error_dwell = processing.dwell(df=df_, cores=7) if __name__ == '__main__' else None\n","        \n","            #----normalize dwell_time for comparison between iaps and pofa\n","            df_dwell['dwell_time'] = df_dwell.apply(lambda x: (x['dwell_time']/4500) \n","            if (x['trialType'] == 'iaps') else (x['dwell_time']/3000), axis=1)\n","            \n"," \t\t\t#-----exclude participants, group by subject:trialType:aoi\n","            # exclude participants \n","            df_dwell = df_dwell[~df_dwell['participant'].isin(exclude)]\n","            # groupby\n","            df_dwell = df_dwell.groupby(['participant','cesd_group','trialType','aoi'])['dwell_time'].mean().reset_index()\n","\n"," \t\t\t#-----run\n","            anova_, anova_result, anova_r, html = model.anova(config=config_, df=df_dwell, y=y, f=f, csv=csv, path=p, effects=effects)\n","            \n","            #-----delete\n","            del y, f, csv, p\n","        \n","        is_['diff'] = True"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#---------------------------------------Linear Mixed Model Regression with random effects: stimulus/dotloc onset error (lmer)\n","        if is_['diff']:\n","            console('Step: Linear Mixed Model Regression', 'red')\n","            effects = {}\n","            \n","            # #----load config\n","            # p = path_['output'] + \"/analysis/config.json\"\n","            # with open(p) as f:\n","            #     config_ = json.loads(f.read())\n","            config_ = config\n","            console('fix config', 'red')   \n","            \n","            #----load data\n","            p = path_['output'] + \"/analysis/error.csv\"\n","            #df_error = pd.read_csv(p_error, float_precision='high')\n","            df_ = pd.read_csv(p, float_precision='high')\n","            \n","            #----parameters            \n","            # dependent variable\n","            y = ['diff_stim','diff_dotloc'] #build models for each IV in list\n","            # fixed effects\n","            effects['fixed'] = {\n","                'os': 'categorical',\n","                'trialType': 'categorical',\n","                'TrialNum': 'factorial'\n","            }\n","            # random effects\n","            effects['random'] = {\n","                'TrialNum': 'factorial',\n","                'participant': 'factorial',\n","            }\n","            \n","            #----save data for access by R and for calculating dwell time\n","            csv = \"onset_data.csv\"\n","            \n","            #----run model for each IV\n","            for _y in y:\n","                # path\n","                p = path_['output'] + \"/analysis/html/model/lmer/\"\n","                # formula\n","                f = \"sqrt(%s) ~ os + trialType + TrialNum + (1+TrialNum|participant)\"%(_y)\n","                # run\n","                lmer_, lmer_result, lmer_r, html = model.lmer(config=config_, df=df_, y=_y, f=f, exclude=exclude, csv=csv, path=p, effects=effects)\n","                \n","            #-----delete\n","            del y, _y, f, csv, p\n","        \n","        is_['mixed'] = True"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#------------------------------------------------------------------------------------------analysis of varience (anova): bias\n","        if is_['mixed']:\n","            effects = {}\n","            \n","            # #----load config\n","            # p = path_['output'] + \"/analysis/config.json\"\n","            # with open(p) as f:\n","            #     config_ = json.loads(f.read())\n","            config_ = config\n","            console('fix config', 'red')   \n","            #----load data\n","            p = path_['output'] + \"/analysis/final_data.csv\"\n","            df_ = pd.read_csv(p, float_precision='high')\n","            \n","            #-----exclude participants, group by subject\n","            # exclude participants\n","            df_ = df_[~df_['participant'].isin(exclude)]\n","            \n","            # groupby\n","            df_ = df_.loc[df_['nested'] == 'trialType']\n","            \n","            #----parameters\n","            # dependent variable\n","            y = ['dp_bias','gaze_bias']\n","            # main effects\n","            effects['main'] = {\n","                'cesd_group': 'categorical',\n","                'trialType': 'categorical'\n","            }\n","            # random effects\n","            effects['random'] = {\n","                'participant': 'categorical'\n","            }\n","            \n","            #----create function for each IV\n","            for _y in y:\n","                console('Step: ANOVA (%s)'%(_y), 'red')\n","                #----save data for access by R\n","                csv = \"%s.csv\"%(_y)\n","                #-----path\n","                p = path_['output'] + \"/analysis/html/model/anova/\"\n","                #-----formula\n","                f = \"%s ~ cesd_group + trialType + (1|participant)\"%(_y)\n","                #-----run\n","                anova_, anova_result, anova_r, html = model.anova(config=config, df=df_, y=_y, f=f, csv=csv, path=p, effects=effects)\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#------------------------------------------------------------------------------------------------------------------------test\n","#------------------------------------------------------------------------draw flowchart of study identification and inclusion\n","is_['flowchart'] = False\n","if is_['flowchart']:\n","    #see https://graphviz.readthedocs.io/en/stable/examples.html\n","    import graphviz as gv\n","    \n","    #path\n","    folder = path_['output'] + \"/analysis/\"\n","    \n","    g = gv.Digraph('G', filename = folder + 'workflow.gv')\n","    g.attr(compound='true')\n","    \n","    with g.subgraph(name='cluster0') as c:\n","        c.edges(['ab', 'ac', 'bd', 'cd'])\n","    \n","    with g.subgraph(name='cluster1') as c:\n","        c.edges(['eg', 'ef'])\n","    \n","    g.edge('b', 'f', lhead='cluster1')\n","    g.edge('d', 'e')\n","    g.edge('c', 'g', ltail='cluster0', lhead='cluster1')\n","    g.edge('c', 'e', ltail='cluster0')\n","    g.edge('d', 'h')\n","    \n","    g.view()\n","pass#------------------------------------------------------------------------------------------------------------------------test\n","#------------------------------------------------------------------------draw flowchart of study identification and inclusion\n","is_['treeview'] = False\n","if is_['treeview']:\n","    #create file tree view\n","    #see https://graphviz.readthedocs.io/en/stable/examples.html\n","    from treelib import Node, Tree\n","    tree = Tree()\n","    tree.create_node(\"Harry\", \"harry\")  # root node\n","    tree.create_node(\"Jane\", \"jane\", parent=\"harry\")\n","    tree.create_node(\"Bill\", \"bill\", parent=\"harry\")\n","    tree.create_node(\"Diane\", \"diane\", parent=\"jane\")\n","    tree.create_node(\"Mary\", \"mary\", parent=\"diane\")\n","    tree.create_node(\"Mark\", \"mark\", parent=\"jane\")\n","    tree.show()\n","pass"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["#--------------------------------------------------------------------------------------------------------------------finished\n","#-------------------------------------------------------------------------------------------------------------garbage collect\n","# import gc\n","# gc.collect()\n","#-------------------------------------------------------------------------------------------------------------quick functions\n","#get list of columns\n","#lst = list(df)\n","#install pip package\n","#from pip._internal import main as _main\n","#_main(['install','statsmodels'])\n","\n","#--------------------------------------------------------------------------------------------------------------iPython Magics\n","#%matplotlib qt5\n","#%matplotlib tk\n","#%matplotlib inline\n","\n","#----------------------------------------------------------------------------------------------------------------other magics\n","# from pdb import set_trace as breakpoint\n","# breakpoint()\n","\n","#----------------------------------------------------------------------------------------------------------------profile code\n","# method 2\n","# from pycallgraph import PyCallGraph\n","# from pycallgraph.output import GraphvizOutput\n","# with PyCallGraph(output=GraphvizOutput()):\n","#     from imhr import plot, processing, raw, redcap\n","#     import imhr.model as model\n","#     import imhr.settings as settings\n","\n","# method 2\n","#profiling run.py\n","\n","# method 3\n","#%load_ext line_profiler\n","\n","# method 34 -- use within jupyter\n","# import os\n","# file = os.getcwd() + '/run.py'\n","# %load_ext snakeviz\n","# %snakeviz prun(file)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}