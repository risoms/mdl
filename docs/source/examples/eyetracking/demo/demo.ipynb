{"cells":[{"cell_type":"markdown","source":[" .. title:: Example setup for Eyelink 1000 Plus, using PsychoPy 3.0\n","  <h5>Example setup for Eyelink 1000 Plus, using PsychoPy 3.0.</h5>"],"metadata":{}},{"cell_type":"markdown","source":[" <div class='info'><p>Created on Wed Feb 13 15:37:43 2019</p>\n"," <p>@author: Semeon Risom</p>\n"," <p>@email: semeon.risom@gmail.com</p>\n"," </div>\n"," Sample code to run SR Research Eyelink eyetracking system. Code is optimized for the Eyelink 1000\n"," Plus (5.0), but should be compatiable with earlier systems."],"metadata":{}},{"cell_type":"markdown","source":[" <ul class=\"list-container\">\n","     <li>\n","         <div class=\"title\">The sequence of operations for implementing the trial is:</div>\n","         <ol class=\"list\">\n","             <li>[Import packages](demo.html#import).</li>\n","             <li>[Initialize the mdl.eyetracking package](demo.html#init).</li>\n","             <li>[Connect to the Eyelink Host](demo.html#connect).</li>\n","             <li>[Set the dominamt eye](demo.html#eye).</li>\n","             <li>[Start calibration](demo.html#calibration).</li>\n","             <li>[Start recording](demo.html#start).</li>\n","             <li>[Stop recording](demo.html#stop).</li>\n","             <li>[Finish recording](demo.html#finish).</li>\n","         </ol>\n","     </li>\n","     <li>\n","         <div class=\"title\">Optional commands include:</div>\n","         <ol>\n","             <li>[Drift correction](demo.html#drift).</li>\n","             <li>[Initiate gaze contigent event](demo.html#gc).</li>\n","             <li>[Collect real-time gaze coordinates from Eyelink](demo.html#sample).</li>\n","             <li>[Send messages to Eyelink](demo.html#message).</li>\n","         </ol>\n","     </li>\n"," </ul>"],"metadata":{}},{"cell_type":"markdown","source":[" <h5 id='import'>Import packages.</h5><br>"],"metadata":{}},{"source":["import os, sys, time\n","sys.path.append(os.path.abspath(os.getcwd() + '../../../../../../..'))\n","from psychopy import visual, core\n","import mdl"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" .. _hyperlink-name: link-block\n"," <h5>Set task parameters, either directly from PsychoPy or created manually.</h5><br>"],"metadata":{}},{"source":["expInfo = {u'condition': u'even', u'participant': u'001', u'dominant eye': u'left', u'corrective': u'False'}\n","subject = expInfo['participant']\n","dominant_eye = expInfo['dominant eye']\n","# `psychopy.core.Clock.CountdownTimer` instance\n","routineTimer = core.CountdownTimer()\n","# `psychopy.visual.window.Window` instance\n","window = visual.Window(size=[1920, 1080], fullscr=False, allowGUI=True, units='pix', winType='pyglet', color=[110,110,110], colorSpace='rgb255')\n","window.flip()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" .. raw:: html\n"," <h5 id='init'>Initialize the [mdl.eyetracking](../../../eyetracking.html#mdl.eyetracking.run) package.</h5>\n"," .. note:: Before initializing, make sure code is placed after PsychoPy window instance has been created in the experiment file.\n"," This window will be used in the calibration function."],"metadata":{}},{"source":["# Initialize mdl.eyetracking()\n","eyetracking = mdl.eyetracking.run(window=window, libraries=True, subject=subject, timer=routineTimer, demo=True)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='connect'>Connect to the Eyelink Host.</h5><br>\n"," This controls the parameters to be used when running the eyetracker."],"metadata":{}},{"source":["param = eyetracking.connect(calibration_type=13)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='eye'>Set the dominamt eye.</h5><br>\n"," This step is required for recieving gaze coordinates from Eyelink->PsychoPy."],"metadata":{}},{"source":["eye_used = eyetracking.set_eye_used(eye=dominant_eye)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='calibration'>Start calibration.</h5><br>\n"," When calibration has been completed, it returns `True`."],"metadata":{}},{"source":["# start calibration\n","calibration = eyetracking.calibration()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# Enter the key \"o\" on the calibration instance. This will begin the task. \n","# The Calibration, Validation, 'task-start' events are controlled by the keyboard.\n","# Calibration (\"c\"), Validation (\"v\"), task-start (\"o\") respectively."],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='print'>(Optional) Print message to console/terminal.</h5><br>\n"," Allows printing color coded messages to console/terminal/cmd. This may be useful for debugging issues."],"metadata":{}},{"source":["eyetracking.console(c=\"blue\", msg=\"eyetracking.calibration() started\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='drift'>(Optional) Drift correction.</h5><br>\n"," This can be done at any point after calibration, including before and after\n"," [eyetracking.start_recording()](../../../eyetracking.rst#mdl.eyetracking.run.start_recording) has started.\n"," When drift correction has been completed, it returns `True`."],"metadata":{}},{"source":["drift = eyetracking.drift_correction()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='start'>Start recording.</h5><br>\n"," .. note:: This should be run at the start of the trial. Also, there is an intentional delay of 150 msec to\n"," allow the Eyelink to buffer gaze samples that will show up in your data."],"metadata":{}},{"source":["# Create stimulus (demonstration purposes only).\n","filename = \"8380.bmp\"\n","path = os.getcwd() + \"/stimuli/\" + filename\n","size = (1024, 768) #image size\n","pos = (window.size[0]/2, window.size[1]/2) #positioning image at center of screen\n","stimulus = visual.ImageStim(win=window, name=\"stimulus\", units='pix', image=path, pos=(0,0), size=size,\n","                            flipHoriz=False, flipVert=False, texRes=128, interpolate=True, depth=-1.0)\n","stimulus.setAutoDraw(True)\n","window.flip()\n","window.flip()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"source":["# start recording\n","eyetracking.start_recording(trial=1, block=1)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='gc'>(Optional) Initiate gaze contigent event.</h5><br>\n"," This is used for realtime data collection from Eyelink->PsychoPy."],"metadata":{}},{"source":["# In the example, a participant is required to look at the bounding cross for a duration\n","# of 2000 msec before continuing the task. If this doesn't happen and a maxinum duration of \n","# 10000 msec has occured, drift correction will be initiated.\n","bound = dict(left=448, top=156, right=1472, bottom=924)\n","eyetracking.gc(bound=bound, t_min=5000, t_max=20000)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='sample'>(Optional) Collect real-time gaze coordinates from Eyelink.</h5><br>\n"," .. note:: Samples need to be collected at an interval of 1000/(sampling rate) msec to prevent oversampling."],"metadata":{}},{"source":["gxy, ps, sample = eyetracking.sample() # get gaze coordinates, pupil size, and sample"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Example use of [eyetracking.sample()](../../../eyetracking.html#mdl.eyetracking.run.sample).</h5>"],"metadata":{}},{"source":["# In our example, the sampling rate of our device (Eyelink 1000 Plus) is 500Hz.\n","s1 = 0 # set current time to 0\n","lgxy = [] # create list of gaze coordinates (demonstration purposes only)\n","s0 = time.clock() # initial timestamp\n","# repeat\n","while True:\n","    # if difference between starting and current time is greater than > 2.01 msec, collect new sample\n","    diff = (s1 - s0)\n","    if diff >= .00201:\n","        gxy, ps, sample = eyetracking.sample() # get gaze coordinates, pupil size, and sample\n","        lgxy.append(gxy) # store in list (not required; demonstration purposes only)\n","        s0 = time.clock() # update starting time\n","    #else set current time\n","    else: \n","        s1 = time.clock()\n","\n","    #break `while` statement if list of gaze coordiantes >= 20 (not required; demonstration purposes only)\n","    if len(lgxy) >= 200: break"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='message'>(Optional) Send messages to Eyelink.</h5><br>\n"," This allows post-hoc processing of event markers (i.e. \"stimulus onset\")."],"metadata":{}},{"source":["# Sending message \"stimulus onset\".\n","eyetracking.send_message(msg=\"stimulus onset\")"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='stop'>Stop recording.</h5><br>\n"," Also (optional) provides trial-level variables to Eyelink."],"metadata":{}},{"cell_type":"markdown","source":[" .. note:: Variables sent are optional. If they being included, they must be in `python dict` format."],"metadata":{}},{"source":["# Prepare variables to be sent to Eyelink\n","variables = dict(stimulus=filename, trial_type='encoding', race=\"black\")\n","# Stop recording\n","eyetracking.stop_recording(trial=1, block=1, variables=variables)"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5 id='finish'>Finish recording.</h5><br>"],"metadata":{}},{"source":["eyetracking.finish_recording()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" <h5>Close PsychoPy.</h5><br>"],"metadata":{}},{"source":["window.close()"],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}